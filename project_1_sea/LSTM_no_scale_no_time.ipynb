{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                10400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10502 (41.02 KB)\n",
      "Trainable params: 10502 (41.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "384/384 [==============================] - 2s 3ms/step - loss: 620.0840 - val_loss: 1.5578\n",
      "Epoch 2/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 1.3492 - val_loss: 1.1639\n",
      "Epoch 3/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.8151 - val_loss: 0.4480\n",
      "Epoch 4/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.1602 - val_loss: 0.0504\n",
      "Epoch 5/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0252 - val_loss: 0.0152\n",
      "Epoch 6/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0131 - val_loss: 0.0308\n",
      "Epoch 7/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0103 - val_loss: 0.0069\n",
      "Epoch 8/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0132\n",
      "Epoch 9/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 10/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 11/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0043\n",
      "Epoch 12/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0112\n",
      "Epoch 13/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0130 - val_loss: 0.0213\n",
      "Epoch 14/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0236 - val_loss: 0.0704\n",
      "Epoch 15/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0409 - val_loss: 0.0704\n",
      "Epoch 16/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0375 - val_loss: 0.1024\n",
      "Epoch 17/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0443 - val_loss: 0.0658\n",
      "Epoch 18/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0538 - val_loss: 0.0132\n",
      "Epoch 19/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0363 - val_loss: 0.0324\n",
      "Epoch 20/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0520 - val_loss: 0.0125\n",
      "Epoch 21/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0520 - val_loss: 0.0366\n",
      "Epoch 22/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0377 - val_loss: 0.1131\n",
      "Epoch 23/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0417 - val_loss: 0.0117\n",
      "Epoch 24/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0224\n",
      "Epoch 25/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0473 - val_loss: 0.0192\n",
      "Epoch 26/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0399 - val_loss: 0.0064\n",
      "Epoch 27/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0409 - val_loss: 0.0082\n",
      "Epoch 28/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0415 - val_loss: 0.0032\n",
      "Epoch 29/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0424 - val_loss: 0.0810\n",
      "Epoch 30/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0423 - val_loss: 0.1050\n",
      "Epoch 31/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0369 - val_loss: 0.0191\n",
      "Epoch 32/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0405 - val_loss: 0.0175\n",
      "Epoch 33/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0403 - val_loss: 0.0161\n",
      "Epoch 34/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0407 - val_loss: 0.0178\n",
      "Epoch 35/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0400 - val_loss: 0.0776\n",
      "Epoch 36/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0380 - val_loss: 0.0024\n",
      "Epoch 37/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0348 - val_loss: 0.0065\n",
      "Epoch 38/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0424 - val_loss: 0.0531\n",
      "Epoch 39/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0379 - val_loss: 0.0549\n",
      "Epoch 40/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0339 - val_loss: 0.0082\n",
      "Epoch 41/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0331 - val_loss: 0.0221\n",
      "Epoch 42/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0408 - val_loss: 0.0289\n",
      "Epoch 43/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0351 - val_loss: 0.0106\n",
      "Epoch 44/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0337 - val_loss: 0.1001\n",
      "Epoch 45/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0397 - val_loss: 0.0038\n",
      "Epoch 46/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0292 - val_loss: 0.0219\n",
      "Epoch 47/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0337 - val_loss: 0.0066\n",
      "Epoch 48/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0415 - val_loss: 0.0138\n",
      "Epoch 49/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0255 - val_loss: 0.0479\n",
      "Epoch 50/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0343 - val_loss: 0.2229\n",
      "Epoch 51/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0347 - val_loss: 0.0921\n",
      "Epoch 52/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0311 - val_loss: 0.0454\n",
      "Epoch 53/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0325 - val_loss: 0.0100\n",
      "Epoch 54/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0340 - val_loss: 0.0122\n",
      "Epoch 55/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0287 - val_loss: 0.1494\n",
      "Epoch 56/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0315 - val_loss: 0.0235\n",
      "Epoch 57/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0302 - val_loss: 0.0033\n",
      "Epoch 58/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0331 - val_loss: 0.1525\n",
      "Epoch 59/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0277 - val_loss: 0.0243\n",
      "Epoch 60/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0340 - val_loss: 0.0286\n",
      "Epoch 61/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0333 - val_loss: 0.0416\n",
      "Epoch 62/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0253 - val_loss: 0.0391\n",
      "Epoch 63/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0299 - val_loss: 0.0998\n",
      "Epoch 64/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0309 - val_loss: 0.0424\n",
      "Epoch 65/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0296 - val_loss: 0.0045\n",
      "Epoch 66/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0285 - val_loss: 0.0427\n",
      "Epoch 67/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0289 - val_loss: 0.0157\n",
      "Epoch 68/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0276 - val_loss: 0.0177\n",
      "Epoch 69/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0303 - val_loss: 0.0386\n",
      "Epoch 70/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0272 - val_loss: 0.0196\n",
      "Epoch 71/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0304 - val_loss: 0.0033\n",
      "Epoch 72/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0252 - val_loss: 0.0273\n",
      "Epoch 73/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0296 - val_loss: 0.0565\n",
      "Epoch 74/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 75/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0261\n",
      "Epoch 76/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0281 - val_loss: 0.0161\n",
      "Epoch 77/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0260 - val_loss: 0.0143\n",
      "Epoch 78/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0318 - val_loss: 0.0113\n",
      "Epoch 79/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0237 - val_loss: 0.0246\n",
      "Epoch 80/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0241 - val_loss: 0.0233\n",
      "Epoch 81/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0265 - val_loss: 0.0045\n",
      "Epoch 82/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0286 - val_loss: 0.0134\n",
      "Epoch 83/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0221 - val_loss: 0.0130\n",
      "Epoch 84/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0253 - val_loss: 0.0413\n",
      "Epoch 85/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0250 - val_loss: 0.0357\n",
      "Epoch 86/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0293 - val_loss: 0.0146\n",
      "Epoch 87/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0239 - val_loss: 0.0147\n",
      "Epoch 88/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0252 - val_loss: 0.1158\n",
      "Epoch 89/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0272 - val_loss: 0.0106\n",
      "Epoch 90/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0207 - val_loss: 0.0041\n",
      "Epoch 91/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0096\n",
      "Epoch 92/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0263 - val_loss: 0.0048\n",
      "Epoch 93/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0214 - val_loss: 0.0147\n",
      "Epoch 94/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0244 - val_loss: 0.0342\n",
      "Epoch 95/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0252 - val_loss: 0.0284\n",
      "Epoch 96/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0263 - val_loss: 0.0877\n",
      "Epoch 97/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0190 - val_loss: 0.0400\n",
      "Epoch 98/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0283 - val_loss: 0.0393\n",
      "Epoch 99/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0213 - val_loss: 0.0384\n",
      "Epoch 100/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0262 - val_loss: 0.0987\n",
      "Epoch 101/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0220 - val_loss: 0.0020\n",
      "Epoch 102/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0238 - val_loss: 0.0184\n",
      "Epoch 103/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0204 - val_loss: 0.0060\n",
      "Epoch 104/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0232 - val_loss: 0.0192\n",
      "Epoch 105/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0224 - val_loss: 0.0266\n",
      "Epoch 106/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0272 - val_loss: 0.0123\n",
      "Epoch 107/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0235 - val_loss: 0.0177\n",
      "Epoch 108/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0196 - val_loss: 0.0158\n",
      "Epoch 109/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0237 - val_loss: 0.0035\n",
      "Epoch 110/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0231 - val_loss: 0.0169\n",
      "Epoch 111/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0230 - val_loss: 0.0150\n",
      "Epoch 112/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0205 - val_loss: 0.0057\n",
      "Epoch 113/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0233 - val_loss: 0.0026\n",
      "Epoch 114/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0212 - val_loss: 0.0120\n",
      "Epoch 115/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0216 - val_loss: 0.0083\n",
      "Epoch 116/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0226 - val_loss: 0.0189\n",
      "Epoch 117/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0247 - val_loss: 0.0097\n",
      "Epoch 118/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0192 - val_loss: 0.0477\n",
      "Epoch 119/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0206 - val_loss: 0.0941\n",
      "Epoch 120/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0257 - val_loss: 0.0130\n",
      "Epoch 121/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0188 - val_loss: 0.0301\n",
      "Epoch 122/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0207 - val_loss: 0.0051\n",
      "Epoch 123/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0210 - val_loss: 0.0719\n",
      "Epoch 124/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0249 - val_loss: 0.0029\n",
      "Epoch 125/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0196 - val_loss: 0.0161\n",
      "Epoch 126/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0216 - val_loss: 0.0075\n",
      "Epoch 127/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0217 - val_loss: 0.0594\n",
      "Epoch 128/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0245 - val_loss: 0.0128\n",
      "Epoch 129/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0210 - val_loss: 0.0109\n",
      "Epoch 130/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0200 - val_loss: 0.0204\n",
      "Epoch 131/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0188 - val_loss: 0.0220\n",
      "Epoch 132/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0246 - val_loss: 0.0155\n",
      "Epoch 133/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0211 - val_loss: 0.0381\n",
      "Epoch 134/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0205 - val_loss: 0.0079\n",
      "Epoch 135/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0205 - val_loss: 0.0703\n",
      "Epoch 136/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0232 - val_loss: 0.0126\n",
      "Epoch 137/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0178 - val_loss: 0.0082\n",
      "Epoch 138/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0207 - val_loss: 0.0156\n",
      "Epoch 139/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0213 - val_loss: 0.0023\n",
      "Epoch 140/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0249 - val_loss: 0.0058\n",
      "Epoch 141/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0175 - val_loss: 0.0265\n",
      "Epoch 142/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0213 - val_loss: 0.0079\n",
      "Epoch 143/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0190 - val_loss: 0.0545\n",
      "Epoch 144/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0233 - val_loss: 0.0105\n",
      "Epoch 145/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0185 - val_loss: 0.0489\n",
      "Epoch 146/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0233 - val_loss: 0.0022\n",
      "Epoch 147/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0191 - val_loss: 0.0061\n",
      "Epoch 148/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0186 - val_loss: 0.0402\n",
      "Epoch 149/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0217 - val_loss: 0.0846\n",
      "Epoch 150/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0195 - val_loss: 0.0062\n",
      "Epoch 151/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0187 - val_loss: 0.0119\n",
      "Epoch 152/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0208 - val_loss: 0.0496\n",
      "Epoch 153/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0208 - val_loss: 0.0018\n",
      "Epoch 154/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0204 - val_loss: 0.0301\n",
      "Epoch 155/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0215 - val_loss: 0.0108\n",
      "Epoch 156/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0192 - val_loss: 0.0165\n",
      "Epoch 157/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0172 - val_loss: 0.0042\n",
      "Epoch 158/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0197 - val_loss: 0.0434\n",
      "Epoch 159/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0193 - val_loss: 0.0033\n",
      "Epoch 160/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0197 - val_loss: 0.0165\n",
      "Epoch 161/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0203 - val_loss: 0.0300\n",
      "Epoch 162/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0180 - val_loss: 0.0471\n",
      "Epoch 163/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0197 - val_loss: 0.0517\n",
      "Epoch 164/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0178 - val_loss: 0.0122\n",
      "Epoch 165/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0194 - val_loss: 0.0180\n",
      "Epoch 166/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0195 - val_loss: 0.0144\n",
      "Epoch 167/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0188 - val_loss: 0.0182\n",
      "Epoch 168/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0194 - val_loss: 0.1096\n",
      "Epoch 169/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0165 - val_loss: 0.0401\n",
      "Epoch 170/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0197 - val_loss: 0.0359\n",
      "Epoch 171/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0194 - val_loss: 0.1012\n",
      "Epoch 172/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0214 - val_loss: 0.0238\n",
      "Epoch 173/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0167 - val_loss: 0.0040\n",
      "Epoch 174/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0192 - val_loss: 0.0030\n",
      "Epoch 175/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0208 - val_loss: 0.0061\n",
      "Epoch 176/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0166 - val_loss: 0.0251\n",
      "Epoch 177/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0173 - val_loss: 0.0149\n",
      "Epoch 178/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0115\n",
      "Epoch 179/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0223 - val_loss: 0.0310\n",
      "Epoch 180/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0157 - val_loss: 0.0507\n",
      "Epoch 181/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0185 - val_loss: 0.0087\n",
      "Epoch 182/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0222 - val_loss: 0.0116\n",
      "Epoch 183/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0154 - val_loss: 0.0044\n",
      "Epoch 184/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0583\n",
      "Epoch 185/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0172 - val_loss: 0.0103\n",
      "Epoch 186/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0080\n",
      "Epoch 187/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0173 - val_loss: 0.0115\n",
      "Epoch 188/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0185 - val_loss: 0.0363\n",
      "Epoch 189/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0225 - val_loss: 0.0061\n",
      "Epoch 190/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 191/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0204 - val_loss: 0.0215\n",
      "Epoch 192/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0152 - val_loss: 0.0361\n",
      "Epoch 193/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0183 - val_loss: 0.0055\n",
      "Epoch 194/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0146 - val_loss: 0.0186\n",
      "Epoch 195/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0212 - val_loss: 0.0058\n",
      "Epoch 196/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0181 - val_loss: 0.0026\n",
      "Epoch 197/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0156 - val_loss: 0.0407\n",
      "Epoch 198/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0200 - val_loss: 0.0379\n",
      "Epoch 199/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0160 - val_loss: 0.0084\n",
      "Epoch 200/200\n",
      "384/384 [==============================] - 1s 2ms/step - loss: 0.0172 - val_loss: 0.0037\n",
      "Test Loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽기\n",
    "df = pd.read_csv('data/data_drifter.csv')\n",
    "\n",
    "# 데이터 분할\n",
    "X = df[['lons', 'lats', 'uo', 'vo', 'u10', 'v10']]\n",
    "y = df[['next_lons', 'next_lats']]\n",
    "\n",
    "# train, test 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#############################\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 모델 구조 확인\n",
    "model.summary()\n",
    "\n",
    "#############################\n",
    "# 3. 학습 및 평가하기\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# 학습\n",
    "model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# 평가\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 과적합 방지하는 코드 추가\n",
    "\n",
    "# # 1. 데이터 불러오기\n",
    "# # 데이터 읽기\n",
    "# df = pd.read_csv('data/data_drifter.csv')\n",
    "\n",
    "# # 데이터 분할\n",
    "# X = df[['time', 'lons', 'lats', 'uo', 'vo', 'u10', 'v10', 'next_time']]\n",
    "# y = df[['next_lons', 'next_lats']]\n",
    "\n",
    "# # train, test 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 2. 모델 구성하기\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1), dropout=0.2))  # Dropout 추가\n",
    "# model.add(Dense(2))\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # 모델 구조 확인\n",
    "# model.summary()\n",
    "\n",
    "# #############################\n",
    "# # 3. 학습 및 평가하기\n",
    "# # reshape input to be 3D [samples, timesteps, features]\n",
    "# X_train = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "# X_test = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# # Early Stopping 콜백 정의\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # 10 epoch 동안 개선이 없으면 중단\n",
    "\n",
    "# # 학습 (Early Stopping 추가)\n",
    "# model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# # 평가\n",
    "# loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(f\"Test Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습된 모델로 경로 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n",
    "    ### 1-1. 초기값 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "drifter = pd.read_csv(\"data/drifter_2016.csv\")\n",
    "\n",
    "# 시간 변환 함수\n",
    "def convert_to_nearest_6hour(year, month, day, hour, minute):\n",
    "    # 데이터 값을 정수형으로 변환\n",
    "    year = int(year)\n",
    "    month = int(month)\n",
    "    day = int(day)\n",
    "    hour = int(hour)\n",
    "    minute = int(minute)\n",
    "\n",
    "    dt = datetime(year, month, day, hour, minute)\n",
    "    base_dt = datetime(2016, 1, 1, 0, 0)\n",
    "    delta = dt - base_dt\n",
    "    \n",
    "    hours_since_base = delta.total_seconds() / 3600\n",
    "    nearest_6hour = round(hours_since_base / 6) * 6\n",
    "\n",
    "    result_time = np.datetime64(base_dt + timedelta(hours=nearest_6hour))\n",
    "\n",
    "    return nearest_6hour, result_time\n",
    "\n",
    "# 결과를 저장할 리스트 생성\n",
    "results = []\n",
    "\n",
    "# .nc 파일 읽기\n",
    "dataset_sea = xr.open_dataset('interpolated_sea_16.nc', engine='netcdf4')\n",
    "dataset_wind = xr.open_dataset('interpolated_wind_16.nc', engine='netcdf4')\n",
    "# 각 시작 지점에 대한 처리\n",
    "for index, row in drifter.iterrows():\n",
    "    time, result_time = convert_to_nearest_6hour(row['Year'], row['Month'], row['Day'], row['Hour'], row['Minute'])\n",
    "    next_time = time + 6\n",
    "    \n",
    "    # uo, vo 값을 가져옴\n",
    "    uo_value = dataset_sea['uo'].sel(time=result_time, longitude=row['Longitude'], latitude=row['Latitude'], method='nearest').item()\n",
    "    vo_value = dataset_sea['vo'].sel(time=result_time, longitude=row['Longitude'], latitude=row['Latitude'], method='nearest').item()\n",
    "\n",
    "    # u10, v10 값을 가져옴\n",
    "    u10_value = dataset_wind['u10'].sel(time=result_time, longitude=row['Longitude'], latitude=row['Latitude'], method='nearest').item()\n",
    "    v10_value = dataset_wind['v10'].sel(time=result_time, longitude=row['Longitude'], latitude=row['Latitude'], method='nearest').item()\n",
    "\n",
    "    # 결과 저장\n",
    "    results.append({\n",
    "        'time': time,\n",
    "        'lons': row['Longitude'],\n",
    "        'lats': row['Latitude'],\n",
    "        'uo': uo_value,\n",
    "        'vo': vo_value,\n",
    "        'u10': u10_value,\n",
    "        'v10': v10_value,\n",
    "        'next_time': next_time\n",
    "    })\n",
    "\n",
    "dataset_sea.close()\n",
    "dataset_wind.close()\n",
    "\n",
    "# 리스트를 DataFrame으로 변환\n",
    "result_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lons</th>\n",
       "      <th>lats</th>\n",
       "      <th>uo</th>\n",
       "      <th>vo</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>next_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1740</td>\n",
       "      <td>127.071833</td>\n",
       "      <td>32.507367</td>\n",
       "      <td>-0.042594</td>\n",
       "      <td>0.163610</td>\n",
       "      <td>-3.698855</td>\n",
       "      <td>-5.244993</td>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1794</td>\n",
       "      <td>126.615817</td>\n",
       "      <td>33.759317</td>\n",
       "      <td>0.111659</td>\n",
       "      <td>0.156357</td>\n",
       "      <td>-1.989050</td>\n",
       "      <td>-1.670222</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1884</td>\n",
       "      <td>129.281933</td>\n",
       "      <td>34.949633</td>\n",
       "      <td>-0.039718</td>\n",
       "      <td>0.288225</td>\n",
       "      <td>-6.011956</td>\n",
       "      <td>-6.245036</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1884</td>\n",
       "      <td>129.212400</td>\n",
       "      <td>34.986667</td>\n",
       "      <td>-0.040380</td>\n",
       "      <td>0.272089</td>\n",
       "      <td>-4.942860</td>\n",
       "      <td>-5.878523</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4722</td>\n",
       "      <td>127.074467</td>\n",
       "      <td>32.516267</td>\n",
       "      <td>0.049979</td>\n",
       "      <td>0.304935</td>\n",
       "      <td>-2.538096</td>\n",
       "      <td>6.621501</td>\n",
       "      <td>4728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4788</td>\n",
       "      <td>129.297233</td>\n",
       "      <td>34.921750</td>\n",
       "      <td>0.203083</td>\n",
       "      <td>0.389139</td>\n",
       "      <td>1.072325</td>\n",
       "      <td>2.255833</td>\n",
       "      <td>4794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4824</td>\n",
       "      <td>129.398283</td>\n",
       "      <td>37.552583</td>\n",
       "      <td>0.025877</td>\n",
       "      <td>0.015028</td>\n",
       "      <td>-3.240538</td>\n",
       "      <td>1.653777</td>\n",
       "      <td>4830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time        lons       lats        uo        vo       u10       v10  \\\n",
       "0  1740  127.071833  32.507367 -0.042594  0.163610 -3.698855 -5.244993   \n",
       "1  1794  126.615817  33.759317  0.111659  0.156357 -1.989050 -1.670222   \n",
       "2  1884  129.281933  34.949633 -0.039718  0.288225 -6.011956 -6.245036   \n",
       "3  1884  129.212400  34.986667 -0.040380  0.272089 -4.942860 -5.878523   \n",
       "4  4722  127.074467  32.516267  0.049979  0.304935 -2.538096  6.621501   \n",
       "5  4788  129.297233  34.921750  0.203083  0.389139  1.072325  2.255833   \n",
       "6  4824  129.398283  37.552583  0.025877  0.015028 -3.240538  1.653777   \n",
       "\n",
       "   next_time  \n",
       "0       1746  \n",
       "1       1800  \n",
       "2       1890  \n",
       "3       1890  \n",
       "4       4728  \n",
       "5       4794  \n",
       "6       4830  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델로 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for index 0...\n",
      "inital value load for index 0...\n",
      "result : 1740.0, 127.07183333333332, 32.50736666666667, -0.042593646328896284, 0.16361024975776672, -3.69885516166687, -5.244993209838867, 1746.0\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 14ms/step667, -0.042593646328896284, 0.16361024975776672, -3.69885516166687, -5.244993209838867, 1746.0, 127.13285064697266, 32.58237075805664predicting for\n",
      "1/1 [==============================] - 0s 14ms/step664, -0.14508268237113953, 0.11114412546157837, -4.157172679901123, -10.76705551147461, 1752.0, 127.18528747558594, 32.65137481689453predicting for\n",
      "1/1 [==============================] - 0s 14ms/step453, -0.12662695348262787, 0.03190178796648979, 0.019129991531372015, -12.014824867248535, 1758.0, 127.22553253173828, 32.712554931640625predicting for\n",
      "1/1 [==============================] - 0s 15ms/step0625, -0.025907501578330994, 0.007112167775630951, 2.584773540496826, -10.68887996673584, 1764.0, 127.2745361328125, 32.77005386352539predicting for\n",
      "1/1 [==============================] - 0s 14ms/step39, -0.0008573941886425018, 0.06260788440704346, 0.7365374565124512, -8.49183177947998, 1770.0, 127.33467102050781, 32.830326080322266predicting for\n",
      "1/1 [==============================] - 0s 15ms/step2266, 0.002115720883011818, 0.08973849564790726, 0.21648716926574707, -7.1313676834106445, 1776.0, 127.39614868164062, 32.89141082763672predicting for\n",
      "1/1 [==============================] - 0s 14ms/step672, -0.048744283616542816, 0.12379778176546097, -2.9234566688537598, -4.187080383300781, 1782.0, 127.45472717285156, 32.9494514465332predicting for\n",
      "1/1 [==============================] - 0s 14ms/step32, -0.014786336570978165, 0.15324892103672028, -2.6709141731262207, -1.1839070320129395, 1788.0, 127.51426696777344, 33.00887680053711predicting for\n",
      "1/1 [==============================] - 0s 14ms/step711, -0.025713352486491203, 0.17603717744350433, -1.5653396844863892, 0.6019556522369385, 1794.0, 127.56363677978516, 33.070404052734375predicting for\n",
      "1/1 [==============================] - 0s 14ms/step4375, -0.01727624610066414, 0.17146341502666473, -0.32320524752140045, 1.6243342161178589, 1800.0, 127.60777282714844, 33.13037872314453predicting for \n",
      "1/1 [==============================] - 0s 14ms/step453, -0.026349125429987907, 0.18564645946025848, -3.5744547843933105, 1.5400667190551758, 1806.0, 127.66569519042969, 33.18662643432617predicting for \n",
      "1/1 [==============================] - 0s 15ms/step617, -0.02619583159685135, 0.1846742033958435, -1.937605857849121, 2.307612180709839, 1812.0, 127.71532440185547, 33.24284362792969predicting for \n",
      "1/1 [==============================] - 0s 16ms/step969, -0.03683828189969063, 0.1708141416311264, -1.660744547843933, 0.6638872623443604, 1818.0, 127.76564025878906, 33.29682159423828predicting for \n",
      "1/1 [==============================] - 0s 14ms/step828, 0.016339046880602837, 0.09749644994735718, -1.8543603420257568, 0.645612359046936, 1824.0, 127.827880859375, 33.33765411376953predicting for \n",
      "1/1 [==============================] - 0s 15ms/step3, 0.008077060803771019, 0.12587173283100128, -3.8559927940368652, -0.037665367126464844, 1830.0, 127.89983367919922, 33.37976837158203predicting for \n",
      "1/1 [==============================] - 0s 15ms/step203, 0.011468791402876377, 0.1549064815044403, -3.9738457202911377, 3.4934494495391846, 1836.0, 127.96588134765625, 33.42268371582031predicting for \n",
      "1/1 [==============================] - 0s 14ms/step031, 0.01754813641309738, 0.14325152337551117, -5.177631378173828, 2.8670268058776855, 1842.0, 128.04025268554688, 33.46145248413086predicting for \n",
      "1/1 [==============================] - 0s 15ms/step086, 0.012775875627994537, 0.23149675130844116, -5.568603992462158, 10.718122482299805, 1848.0, 128.09764099121094, 33.451171875predicting for \n",
      "1/1 [==============================] - 0s 15ms/step0.062416356056928635, 0.24014794826507568, -0.3054337501525879, 9.939409255981445, 1854.0, 128.1460418701172, 33.50748062133789predicting for \n",
      "1/1 [==============================] - 0s 15ms/step89, 0.21213693916797638, 0.08632926642894745, 5.115809440612793, 3.432533025741577, 1860.0, 128.2158966064453, 33.551910400390625predicting for \n",
      "1/1 [==============================] - 0s 14ms/step625, 0.16360484063625336, 0.012587986886501312, 4.083191394805908, -2.2753241062164307, 1866.0, 128.292236328125, 33.58528137207031predicting for \n",
      "1/1 [==============================] - 0s 14ms/step1, 0.1415334939956665, -0.03639061376452446, 3.7380502223968506, -3.6601545810699463, 1872.0, 128.36769104003906, 33.61030578613281predicting for \n",
      "1/1 [==============================] - 0s 14ms/step281, 0.11158452183008194, -0.04142361134290695, 0.4456459879875183, -5.63181209564209, 1878.0, 128.45570373535156, 33.631221771240234predicting for \n",
      "1/1 [==============================] - 0s 13ms/step0234, 0.0708603709936142, -0.006475858390331268, -4.333017349243164, -5.466322898864746, 1884.0, 128.55587768554688, 33.650169372558594predicting for \n",
      "1/1 [==============================] - 0s 14ms/step8594, 0.0634072870016098, -0.09647434204816818, -4.613619804382324, -3.744422197341919, 1890.0, 128.64927673339844, 33.65268325805664predicting for \n",
      "1/1 [==============================] - 0s 15ms/step664, 0.0746319591999054, -0.08884542435407639, -5.316061973571777, -3.2144505977630615, 1896.0, 128.74681091308594, 33.65536880493164predicting for \n",
      "1/1 [==============================] - 0s 14ms/step164, 0.049348097294569016, -0.06264802068471909, -5.349734306335449, -3.7170097827911377, 1902.0, 128.8401336669922, 33.66236114501953predicting for \n",
      "1/1 [==============================] - 0s 14ms/step53, 0.04035847261548042, -0.0330803282558918, -6.258886814117432, -4.611464500427246, 1908.0, 128.93785095214844, 33.67338943481445predicting for \n",
      "1/1 [==============================] - 0s 14ms/step445, 0.03168885409832001, -0.037897784262895584, -6.822897911071777, -5.748568534851074, 1914.0, 129.0382843017578, 33.68366241455078predicting for \n",
      "1/1 [==============================] - 0s 13ms/step78, -0.05129845067858696, -0.04571443796157837, -7.150267601013184, -5.8592329025268555, 1920.0, 129.12094116210938, 33.691349029541016predicting for \n",
      "1/1 [==============================] - 0s 14ms/step1016, -0.05051542446017265, -0.04943529888987541, -6.287882328033447, -6.3861589431762695, 1926.0, 129.20077514648438, 33.700313568115234predicting for \n",
      "1/1 [==============================] - 0s 14ms/step5234, -0.020120665431022644, -0.058618828654289246, -4.331146717071533, -6.5628156661987305, 1932.0, 129.2788848876953, 33.7111930847168predicting for \n",
      "1/1 [==============================] - 0s 14ms/step8, -0.041455235332250595, 0.04067894443869591, -2.7186167240142822, -4.524150848388672, 1938.0, 129.34254455566406, 33.737979888916016predicting for \n",
      "1/1 [==============================] - 0s 14ms/step6016, 0.018998093903064728, 0.048250313848257065, -0.09872317314147949, -2.4570577144622803, 1944.0, 129.40394592285156, 33.76785659790039predicting for \n",
      "1/1 [==============================] - 0s 14ms/step039, 0.1558944135904312, 0.05930151790380478, 2.081559419631958, -0.44072818756103516, 1950.0, 129.48220825195312, 33.80259323120117predicting for \n",
      "1/1 [==============================] - 0s 15ms/step117, 0.21085500717163086, 0.05159822851419449, 5.402023792266846, 0.4527108669281006, 1956.0, 129.5556182861328, 33.83998107910156predicting for \n",
      "1/1 [==============================] - 0s 15ms/step56, 0.18838880956172943, 0.08290811628103256, 6.921955108642578, 2.2243597507476807, 1962.0, 129.6139678955078, 33.88108444213867predicting for \n",
      "1/1 [==============================] - 0s 14ms/step67, 0.14605814218521118, 0.05009055510163307, 6.581490516662598, 0.14711403846740712, 1968.0, 129.66915893554688, 33.916080474853516predicting for \n",
      "1/1 [==============================] - 0s 14ms/step3516, 0.08030384033918381, 0.05256480351090431, -2.225691318511963, -3.985041379928589, 1974.0, 129.75914001464844, 33.941986083984375predicting for \n",
      "1/1 [==============================] - 0s 15ms/step4375, 0.023959780111908913, -0.05521303787827492, -1.4297150373458862, -6.94354248046875, 1980.0, 129.8370819091797, 33.9531364440918predicting for \n",
      "1/1 [==============================] - 0s 14ms/step8, -0.08114838600158691, -0.020349770784378052, -2.8289871215820312, -5.394238471984863, 1986.0, 129.89407348632812, 33.96524429321289predicting for \n",
      "1/1 [==============================] - 0s 14ms/step289, -0.09139754623174667, -0.0035414251033216715, -5.7089056968688965, -4.843961715698242, 1992.0, 129.96038818359375, 33.9750862121582predicting for \n",
      "1/1 [==============================] - 0s 14ms/step82, -0.26533225178718567, -0.0521215982735157, -8.986344337463379, -10.059412002563477, 1998.0, 130.0109100341797, 33.97743225097656predicting for \n",
      "1/1 [==============================] - 0s 14ms/step56, -0.28103673458099365, -0.02437262795865535, -6.784549236297607, -9.442126274108887, 2004.0, 130.0470733642578, 33.98716354370117predicting for \n",
      "1/1 [==============================] - 0s 15ms/step17, -0.2481130063533783, 0.003030845895409584, -6.645183086395264, -8.40857982635498, 2010.0, 130.08877563476562, 33.99988555908203predicting for \n",
      "1/1 [==============================] - 0s 14ms/step203, -0.17043466866016388, 0.049496475607156754, -7.29898738861084, -5.518101692199707, 2016.0, 130.1461639404297, 34.01566696166992predicting for \n",
      "1/1 [==============================] - 0s 14ms/step92, -0.053505152463912964, 0.0758289247751236, -7.443965435028076, -3.7911245822906494, 2022.0, 130.22796630859375, 34.034080505371094predicting for \n",
      "1/1 [==============================] - 0s 15ms/step1094, -0.026317251846194267, 0.05709082633256912, -4.667869567871094, -5.433834075927734, 2028.0, 130.30703735351562, 34.05515670776367predicting for \n",
      "1/1 [==============================] - 0s 14ms/step367, -0.012029130011796951, 0.12600180506706238, -4.739891052246094, -3.622589349746704, 2034.0, 130.38719177246094, 34.085384368896484predicting for \n",
      "1/1 [==============================] - 0s 14ms/step6484, 0.04128013551235199, 0.14448614418506622, -4.806300163269043, -0.9686694145202637, 2040.0, 130.47415161132812, 34.11641311645508predicting for \n",
      "1/1 [==============================] - 0s 14ms/step508, 0.07283364981412888, 0.1770385056734085, -3.1376500129699707, 2.7462093830108643, 2046.0, 130.5531005859375, 34.152061462402344predicting for \n",
      "1/1 [==============================] - 0s 14ms/step344, 0.014668561518192291, 0.10787452012300491, -1.3445988893508911, -2.0326740741729736, 2052.0, 130.6206512451172, 34.18115997314453predicting for \n",
      "1/1 [==============================] - 0s 15ms/step53, 0.10480510257184505, 0.023803293704986572, 1.3866002559661865, -0.23056697845458984, 2058.0, 130.69036865234375, 34.2000617980957predicting for \n",
      "1/1 [==============================] - 0s 15ms/step57, 0.17141208052635193, 0.09782574325799942, 2.919625997543335, 1.6690062284469604, 2064.0, 130.76556396484375, 34.232383728027344predicting for \n",
      "result : 2064.0, 130.76556396484375, 34.232383728027344, nan, nan, 5.684497356414795, 3.0162715911865234, 2070.0, nan, nanEncountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 0 completed.\n",
      "Predicting for index 1...\n",
      "inital value load for index 1...\n",
      "result : 1794.0, 126.61581666666666, 33.75931666666666, 0.11165913939476013, 0.15635666251182556, -1.9890496730804443, -1.6702220439910889, 1800.0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step666, 0.11165913939476013, 0.15635666251182556, -1.9890496730804443, -1.6702220439910889, 1800.0, 126.71794891357422, 33.7963752746582predicting for\n",
      "1/1 [==============================] - 0s 14ms/step82, 0.12133179605007172, 0.17183169722557068, -3.37429141998291, 2.241619348526001, 1806.0, 126.81975555419922, 33.830772399902344predicting for\n",
      "1/1 [==============================] - 0s 15ms/step2344, 0.1667293906211853, 0.1400805562734604, -1.6513911485671997, 0.06183123588562012, 1812.0, 126.92901611328125, 33.863792419433594predicting for\n",
      "1/1 [==============================] - 0s 17ms/step3594, 0.16363267600536346, 0.1465485841035843, -1.165948510169983, 0.8314070701599121, 1818.0, 127.0338134765625, 33.89762496948242predicting for\n",
      "1/1 [==============================] - 0s 14ms/step42, 0.21376563608646393, 0.13300742208957672, -1.5522449016571045, 0.8050100803375244, 1824.0, 127.15179443359375, 33.928836822509766predicting for\n",
      "1/1 [==============================] - 0s 14ms/step9766, 0.20208434760570526, 0.1253817230463028, -3.8587987422943115, -0.3960561752319336, 1830.0, 127.28011322021484, 33.956214904785156predicting for\n",
      "1/1 [==============================] - 0s 15ms/step5156, 0.26255008578300476, 0.1525135189294815, -3.844768524169922, 2.83859920501709, 1836.0, 127.41522216796875, 33.98600387573242predicting for\n",
      "1/1 [==============================] - 0s 15ms/step242, 0.2521768808364868, 0.14251606166362762, -5.010204792022705, 0.2202136516571045, 1842.0, 127.55915069580078, 34.01411056518555predicting for\n",
      "1/1 [==============================] - 0s 14ms/step555, 0.263960063457489, 0.23841045796871185, -6.065270900726318, 4.368613243103027, 1848.0, 127.70279693603516, 34.053321838378906predicting for\n",
      "1/1 [==============================] - 0s 14ms/step8906, 0.3453792929649353, 0.19355110824108124, -0.4896961450576782, 9.39217758178711, 1854.0, 127.82713317871094, 34.09028244018555predicting for \n",
      "1/1 [==============================] - 0s 14ms/step555, 0.2957146465778351, 0.1514987349510193, 3.155332088470459, 2.0710537433624268, 1860.0, 127.94050598144531, 34.12871170043945predicting for \n",
      "1/1 [==============================] - 0s 15ms/step945, 0.25763896107673645, 0.12402409315109253, 1.8065688610076904, -2.2834460735321045, 1866.0, 128.06137084960938, 34.16332244873047predicting for \n",
      "1/1 [==============================] - 0s 15ms/step047, 0.2606794238090515, 0.09171050041913986, 2.7681005001068115, -3.392122983932495, 1872.0, 128.18063354492188, 34.19425964355469predicting for \n",
      "1/1 [==============================] - 0s 15ms/step469, 0.24268031120300293, 0.0792941302061081, 0.18655622005462646, -5.502872467041016, 1878.0, 128.3119659423828, 34.2215461730957predicting for \n",
      "1/1 [==============================] - 0s 15ms/step7, 0.2354559451341629, 0.00720599852502346, -4.2600603103637695, -2.779914140701294, 1884.0, 128.45321655273438, 34.228759765625predicting for \n",
      "1/1 [==============================] - 0s 14ms/step5, 0.1930721253156662, 0.013316065073013306, -7.029608726501465, -3.462176561355591, 1890.0, 128.59841918945312, 34.232688903808594predicting for \n",
      "1/1 [==============================] - 0s 14ms/step8594, 0.20419231057167053, -0.0737161934375763, -6.1803178787231445, -3.1251065731048584, 1896.0, 128.7393341064453, 34.223751068115234predicting for \n",
      "1/1 [==============================] - 0s 14ms/step234, 0.20275846123695374, -0.04214608669281006, -5.790280342102051, -3.6093909740448, 1902.0, 128.87957763671875, 34.220699310302734predicting for \n",
      "1/1 [==============================] - 0s 14ms/step2734, 0.17030198872089386, 0.045477647334337234, -6.455308437347412, -3.976919412612915, 1908.0, 129.01773071289062, 34.230430603027344predicting for \n",
      "1/1 [==============================] - 0s 14ms/step7344, 0.04045179486274719, 0.1294788420200348, -7.007160663604736, -4.1129655838012695, 1914.0, 129.13009643554688, 34.25239562988281predicting for \n",
      "1/1 [==============================] - 0s 15ms/step281, 0.026194609701633453, 0.2740902304649353, -6.445955276489258, -4.554609298706055, 1920.0, 129.24107360839844, 34.29947280883789predicting for \n",
      "1/1 [==============================] - 0s 13ms/step789, 0.004300223663449286, 0.27075091004371643, -5.378729820251465, -5.792224884033203, 1926.0, 129.3450927734375, 34.348392486572266predicting for \n",
      "result : 1926.0, 129.3450927734375, 34.348392486572266, nan, nan, -3.60064435005188, -4.589128494262695, 1932.0, nan, nanEncountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 1 completed.\n",
      "Predicting for index 2...\n",
      "inital value load for index 2...\n",
      "result : 1884.0, 129.28193333333334, 34.94963333333333, -0.03971831128001213, 0.28822505474090576, -6.011956214904785, -6.2450361251831055, 1890.0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step333, -0.03971831128001213, 0.28822505474090576, -6.011956214904785, -6.2450361251831055, 1890.0, 129.38381958007812, 34.999488830566406predicting for\n",
      "1/1 [==============================] - 0s 14ms/step6406, -0.011054821079596877, 0.2926739454269409, -4.625779151916504, -5.8490800857543945, 1896.0, 129.48583984375, 35.051090240478516predicting for\n",
      "1/1 [==============================] - 0s 15ms/step6, -0.0038754499983042487, 0.3173121213912964, -5.924969673156738, -5.172909736633301, 1902.0, 129.59449768066406, 35.104164123535156predicting for\n",
      "1/1 [==============================] - 0s 13ms/step5156, -0.05213931202888489, 0.22645998001098633, -5.761284828186035, -5.5729265213012695, 1908.0, 129.68980407714844, 35.14199447631836predicting for\n",
      "1/1 [==============================] - 0s 15ms/step836, -0.04386047273874283, 0.23362809419631958, -6.414153575897217, -4.9860992431640625, 1914.0, 129.7889404296875, 35.17918395996094predicting for\n",
      "1/1 [==============================] - 0s 14ms/step94, -0.09909343719482422, 0.02797352708876133, -4.719313621520996, -5.373932838439941, 1920.0, 129.863525390625, 35.18465042114258predicting for\n",
      "1/1 [==============================] - 0s 14ms/step8, -0.11108117550611496, 0.011878800578415394, -4.120694637298584, -5.325200080871582, 1926.0, 129.93197631835938, 35.188323974609375predicting for\n",
      "1/1 [==============================] - 0s 15ms/step9375, -0.07261784374713898, 0.0166300218552351, -2.4305312633514404, -3.935293436050415, 1932.0, 129.99916076660156, 35.19334030151367predicting for\n",
      "1/1 [==============================] - 0s 15ms/step367, -0.00972558930516243, 0.09532592445611954, -0.8367080688476562, 2.633514404296875, 1938.0, 130.0607452392578, 35.20762634277344predicting for\n",
      "1/1 [==============================] - 0s 15ms/step44, 0.09620723873376846, -0.0014526434242725407, 5.72939395904541, 2.098466157913208, 1944.0, 130.11744689941406, 35.21232604980469predicting for \n",
      "1/1 [==============================] - 0s 15ms/step469, 0.09138895571231842, 0.005864265374839306, 5.052206039428711, 2.999011993408203, 1950.0, 130.17410278320312, 35.21696853637695predicting for \n",
      "1/1 [==============================] - 0s 14ms/step695, 0.20395779609680176, 0.014344938099384308, 7.486901760101318, 5.765627384185791, 1956.0, 130.23992919921875, 35.221012115478516predicting for \n",
      "1/1 [==============================] - 0s 15ms/step8516, 0.15372446179389954, -0.00446842797100544, 8.0275297164917, 3.3442044258117676, 1962.0, 130.29653930664062, 35.22380828857422predicting for \n",
      "1/1 [==============================] - 0s 15ms/step422, -0.03161238133907318, -0.005018799100071192, -3.1376500129699707, -6.411540985107422, 1968.0, 130.38174438476562, 35.225467681884766predicting for \n",
      "1/1 [==============================] - 0s 14ms/step4766, -0.05811143293976784, 0.03394397720694542, -4.152496337890625, -5.971927642822266, 1974.0, 130.4646453857422, 35.23175811767578predicting for \n",
      "1/1 [==============================] - 0s 14ms/step78, -0.04488435760140419, 0.01602194458246231, -3.30414080619812, -6.447074890136719, 1980.0, 130.547607421875, 35.23648452758789predicting for \n",
      "1/1 [==============================] - 0s 14ms/step9, -0.16337132453918457, 0.16042391955852509, -7.082923412322998, -4.883557319641113, 1986.0, 130.61776733398438, 35.259788513183594predicting for \n",
      "1/1 [==============================] - 0s 14ms/step3594, -0.10097149014472961, 0.052681438624858856, -7.169909954071045, -8.78219985961914, 1992.0, 130.71006774902344, 35.26753234863281predicting for \n",
      "1/1 [==============================] - 0s 14ms/step281, -0.13020242750644684, 0.028155164793133736, -6.503946304321289, -8.887787818908691, 1998.0, 130.79180908203125, 35.27256393432617predicting for \n",
      "1/1 [==============================] - 0s 15ms/step617, -0.014903794974088669, 0.05981888994574547, -4.19365119934082, -8.920276641845703, 2004.0, 130.89219665527344, 35.2847900390625predicting for \n",
      "1/1 [==============================] - 0s 15ms/step25, -0.025529634207487106, 0.08410786837339401, -5.2421698570251465, -7.2511701583862305, 2010.0, 130.9912567138672, 35.29764175415039predicting for \n",
      "1/1 [==============================] - 0s 15ms/step39, 0.03532097861170769, 0.09296391159296036, -4.393814563751221, -6.293768882751465, 2016.0, 131.09912109375, 35.31180953979492predicting for \n",
      "1/1 [==============================] - 0s 14ms/step, 0.05565967038273811, 0.08401510119438171, -4.335823059082031, -5.365811347961426, 2022.0, 131.2091064453125, 35.3234977722168predicting for \n",
      "1/1 [==============================] - 0s 14ms/step8, 0.1079203188419342, 0.09842819720506668, -2.896331548690796, -4.42059326171875, 2028.0, 131.32313537597656, 35.33869552612305predicting for \n",
      "1/1 [==============================] - 0s 14ms/step305, 0.11153080314397812, -0.03283875808119774, -4.122565269470215, -2.1920716762542725, 2034.0, 131.4348907470703, 35.32881164550781predicting for \n",
      "1/1 [==============================] - 0s 14ms/step81, 0.1539459526538849, -0.024073319509625435, -1.9254463911056519, -0.5341331958770752, 2040.0, 131.54283142089844, 35.322364807128906predicting for \n",
      "1/1 [==============================] - 0s 15ms/step8906, 0.15927031636238098, -0.016410047188401226, -4.668805122375488, 2.2182681560516357, 2046.0, 131.65740966796875, 35.310874938964844predicting for \n",
      "1/1 [==============================] - 0s 14ms/step4844, 0.12396032363176346, -0.05471835006028414, -3.494950532913208, -0.9179058074951172, 2052.0, 131.76438903808594, 35.297122955322266predicting for \n",
      "1/1 [==============================] - 0s 15ms/step2266, 0.07822496443986893, 0.01746021769940853, -5.918422222137451, -1.3849308490753174, 2058.0, 131.87353515625, 35.29117965698242predicting for \n",
      "1/1 [==============================] - 0s 14ms/step, 0.18200808763504028, 0.01978706754744053, -2.3781521320343018, 0.6080472469329834, 2064.0, 131.98643493652344, 35.28990936279297predicting for \n",
      "1/1 [==============================] - 0s 15ms/step297, 0.2469329535961151, 0.014059395529329777, 1.8972970247268677, 4.343231678009033, 2070.0, 132.0860595703125, 35.29148483276367predicting for \n",
      "1/1 [==============================] - 0s 15ms/step67, 0.2695656418800354, 0.04558579623699188, 5.315037250518799, 2.4233529567718506, 2076.0, 132.18052673339844, 35.303131103515625predicting for \n",
      "1/1 [==============================] - 0s 14ms/step5625, 0.2413094937801361, 0.06003011018037796, 2.3696446418762207, 1.471028208732605, 2082.0, 132.28411865234375, 35.31418228149414predicting for \n",
      "1/1 [==============================] - 0s 14ms/step414, 0.23853245377540588, 0.13118906319141388, 1.3819235563278198, 1.37153160572052, 2088.0, 132.39320373535156, 35.33523178100586predicting for \n",
      "1/1 [==============================] - 0s 14ms/step586, 0.2452586591243744, 0.1496438980102539, 1.931904673576355, 3.852855682373047, 2094.0, 132.49574279785156, 35.35789108276367predicting for \n",
      "1/1 [==============================] - 0s 15ms/step367, 0.27237072587013245, 0.025030694901943207, 6.602067947387695, 0.7887656688690186, 2100.0, 132.58737182617188, 35.36819076538086predicting for \n",
      "result : 2100.0, 132.58737182617188, 35.36819076538086, nan, nan, 3.217064619064331, 2.6923999786376953, 2106.0, nan, nanEncountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 2 completed.\n",
      "Predicting for index 3...\n",
      "inital value load for index 3...\n",
      "result : 1884.0, 129.2124, 34.986666666666665, -0.040380340069532394, 0.27208882570266724, -4.942860126495361, -5.878522872924805, 1890.0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step40380340069532394, 0.27208882570266724, -4.942860126495361, -5.878522872924805, 1890.0, 129.3084259033203, 35.034881591796875predicting for\n",
      "1/1 [==============================] - 0s 14ms/step875, 0.016161900013685226, 0.30602896213531494, -4.625779151916504, -5.8490800857543945, 1896.0, 129.41757202148438, 35.08866882324219predicting for\n",
      "1/1 [==============================] - 0s 16ms/step219, -0.0038754499983042487, 0.3173121213912964, -5.460104465484619, -4.7515716552734375, 1902.0, 129.52342224121094, 35.142059326171875predicting for\n",
      "1/1 [==============================] - 0s 14ms/step1875, -0.05213931202888489, 0.22645998001098633, -5.761284828186035, -5.5729265213012695, 1908.0, 129.61898803710938, 35.17988586425781predicting for\n",
      "1/1 [==============================] - 0s 14ms/step781, -0.04386047273874283, 0.23362809419631958, -6.041887283325195, -4.651060104370117, 1914.0, 129.71592712402344, 35.21733474731445predicting for\n",
      "1/1 [==============================] - 0s 14ms/step445, -0.011498878709971905, 0.22220264375209808, -4.719313621520996, -5.373932838439941, 1920.0, 129.81643676757812, 35.25474166870117predicting for\n",
      "1/1 [==============================] - 0s 14ms/step117, -0.068360835313797, 0.04705557972192764, -3.493079900741577, -4.6835479736328125, 1926.0, 129.89234924316406, 35.263755798339844predicting for\n",
      "1/1 [==============================] - 0s 14ms/step9844, -0.03160761296749115, 0.0548224113881588, -3.102107048034668, -2.302736520767212, 1932.0, 129.9700469970703, 35.27207946777344predicting for\n",
      "1/1 [==============================] - 0s 14ms/step44, 0.037220632773824036, 0.1339421570301056, -0.17635655403137207, 3.979764461517334, 1938.0, 130.03822326660156, 35.292259216308594predicting for\n",
      "1/1 [==============================] - 0s 13ms/step8594, 0.11724971234798431, -0.03184908255934715, 6.207353591918945, 2.58782696723938, 1944.0, 130.09664916992188, 35.291046142578125predicting for \n",
      "1/1 [==============================] - 0s 14ms/step8125, 0.10238798707723618, -0.03161212056875229, 4.958672046661377, 2.5248801708221436, 1950.0, 130.15725708007812, 35.28969955444336predicting for \n",
      "1/1 [==============================] - 0s 13ms/step336, 0.2277912199497223, -0.010397493839263916, 6.9546918869018555, 6.366668224334717, 1956.0, 130.22984313964844, 35.28926086425781predicting for \n",
      "1/1 [==============================] - 0s 16ms/step781, 0.15875005722045898, -0.03700167778879404, 7.596336841583252, 3.1076462268829346, 1962.0, 130.2900848388672, 35.28672790527344predicting for \n",
      "1/1 [==============================] - 0s 14ms/step44, -0.035319238901138306, -0.04823266342282295, -4.555628776550293, -6.695816993713379, 1968.0, 130.38079833984375, 35.279361724853516predicting for \n",
      "1/1 [==============================] - 0s 14ms/step3516, -0.04573119059205055, -0.02011938765645027, -4.152496337890625, -5.971927642822266, 1974.0, 130.4658966064453, 35.27646255493164predicting for \n",
      "1/1 [==============================] - 0s 14ms/step64, -0.03052876889705658, -0.041575927287340164, -3.30414080619812, -6.447074890136719, 1980.0, 130.55136108398438, 35.27151870727539predicting for \n",
      "1/1 [==============================] - 0s 15ms/step539, -0.08310248702764511, 0.12291887402534485, -7.082923412322998, -4.883557319641113, 1986.0, 130.6405792236328, 35.28707504272461predicting for \n",
      "1/1 [==============================] - 0s 15ms/step61, -0.10097149014472961, 0.052681438624858856, -7.169909954071045, -8.78219985961914, 1992.0, 130.7330322265625, 35.294681549072266predicting for \n",
      "1/1 [==============================] - 0s 15ms/step266, -0.13020242750644684, 0.028155164793133736, -6.503946304321289, -8.887787818908691, 1998.0, 130.8148956298828, 35.29957962036133predicting for \n",
      "1/1 [==============================] - 0s 13ms/step33, -0.014903794974088669, 0.05981888994574547, -4.19365119934082, -8.920276641845703, 2004.0, 130.9154510498047, 35.311676025390625predicting for \n",
      "1/1 [==============================] - 0s 14ms/step625, -0.025529634207487106, 0.08410786837339401, -5.2421698570251465, -7.2511701583862305, 2010.0, 131.01463317871094, 35.324398040771484predicting for \n",
      "1/1 [==============================] - 0s 14ms/step1484, 0.04476645961403847, 0.07037021219730377, -4.393814563751221, -6.293768882751465, 2016.0, 131.12442016601562, 35.33470153808594predicting for \n",
      "1/1 [==============================] - 0s 14ms/step594, 0.05565967038273811, 0.08401510119438171, -4.335823059082031, -5.365811347961426, 2022.0, 131.23451232910156, 35.34626388549805predicting for \n",
      "1/1 [==============================] - 0s 14ms/step805, 0.1079203188419342, 0.09842819720506668, -2.896331548690796, -4.42059326171875, 2028.0, 131.3486785888672, 35.3613395690918predicting for \n",
      "1/1 [==============================] - 0s 16ms/step8, 0.11153080314397812, -0.03283875808119774, -4.122565269470215, -2.1920716762542725, 2034.0, 131.46060180664062, 35.351322174072266predicting for \n",
      "1/1 [==============================] - 0s 14ms/step2266, 0.1539459526538849, -0.024073319509625435, -1.9254463911056519, -0.5341331958770752, 2040.0, 131.56866455078125, 35.344749450683594predicting for \n",
      "1/1 [==============================] - 0s 14ms/step3594, 0.15927031636238098, -0.016410047188401226, -4.668805122375488, 2.2182681560516357, 2046.0, 131.68338012695312, 35.3331298828125predicting for \n",
      "1/1 [==============================] - 0s 14ms/step25, 0.12396032363176346, -0.05471835006028414, -3.220895290374756, -1.9656660556793213, 2052.0, 131.79177856445312, 35.32050323486328predicting for \n",
      "1/1 [==============================] - 0s 14ms/step328, 0.07822496443986893, 0.01746021769940853, -5.918422222137451, -1.3849308490753174, 2058.0, 131.90109252929688, 35.314430236816406predicting for \n",
      "1/1 [==============================] - 0s 14ms/step6406, 0.18200808763504028, 0.01978706754744053, -2.3781521320343018, 0.6080472469329834, 2064.0, 132.01416015625, 35.313026428222656predicting for \n",
      "1/1 [==============================] - 0s 14ms/step6, 0.2432018369436264, 0.09042651951313019, 1.8972970247268677, 4.343231678009033, 2070.0, 132.11497497558594, 35.326541900634766predicting for \n",
      "1/1 [==============================] - 0s 14ms/step4766, 0.2695656418800354, 0.04558579623699188, 5.315037250518799, 2.4233529567718506, 2076.0, 132.20974731445312, 35.337982177734375predicting for \n",
      "1/1 [==============================] - 0s 14ms/step4375, 0.2413094937801361, 0.06003011018037796, 2.3696446418762207, 1.471028208732605, 2082.0, 132.31365966796875, 35.3488655090332predicting for \n",
      "1/1 [==============================] - 0s 14ms/step32, 0.23853245377540588, 0.13118906319141388, 1.3819235563278198, 1.37153160572052, 2088.0, 132.4230499267578, 35.3697624206543predicting for \n",
      "1/1 [==============================] - 0s 14ms/step3, 0.2452586591243744, 0.1496438980102539, 1.931904673576355, 3.852855682373047, 2094.0, 132.52587890625, 35.392276763916016predicting for \n",
      "result : 2094.0, 132.52587890625, 35.392276763916016, nan, nan, 6.602067947387695, 0.7887656688690186, 2100.0, nan, nanEncountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 3 completed.\n",
      "Predicting for index 4...\n",
      "inital value load for index 4...\n",
      "result : 4722.0, 127.07446666666668, 32.51626666666667, 0.049979022704064846, 0.30493471026420593, -2.538095712661743, 6.6215009689331055, 4728.0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step667, 0.049979022704064846, 0.30493471026420593, -2.538095712661743, 6.6215009689331055, 4728.0, 127.12652587890625, 32.607398986816406predicting for\n",
      "1/1 [==============================] - 0s 15ms/step6406, 0.15386778116226196, 0.20761580765247345, 3.8736748695373535, 5.587954521179199, 4734.0, 127.17427825927734, 32.69038009643555predicting for\n",
      "1/1 [==============================] - 0s 15ms/step555, 0.1483999788761139, 0.13295814394950867, 7.1520490646362305, 0.7857198715209961, 4740.0, 127.21697998046875, 32.76570510864258predicting for\n",
      "1/1 [==============================] - 0s 15ms/step258, 0.10597115010023117, 0.09448617696762085, 6.158715724945068, -0.09858179092407227, 4746.0, 127.25750732421875, 32.83153533935547predicting for\n",
      "1/1 [==============================] - 0s 14ms/step547, 0.0696272999048233, 0.14037705957889557, 6.019350051879883, -1.1422810554504395, 4752.0, 127.29534149169922, 32.9029541015625predicting for\n",
      "1/1 [==============================] - 0s 14ms/step25, 0.03227005526423454, 0.17004062235355377, 0.7112832069396973, -2.6134097576141357, 4758.0, 127.35424041748047, 32.97200012207031predicting for\n",
      "1/1 [==============================] - 0s 14ms/step031, 0.06448325514793396, 0.21016497910022736, -0.1716797947883606, 2.273092746734619, 4764.0, 127.41456604003906, 33.041378021240234predicting for\n",
      "1/1 [==============================] - 0s 14ms/step0234, 0.047647714614868164, 0.22229747474193573, 1.756995677947998, 0.7572922706604004, 4770.0, 127.4675064086914, 33.1141357421875predicting for\n",
      "1/1 [==============================] - 0s 13ms/step5, 0.04134652018547058, 0.22905223071575165, -0.20067542791366577, 0.8578041791915894, 4776.0, 127.52873229980469, 33.18346405029297predicting for\n",
      "1/1 [==============================] - 0s 14ms/step297, 0.009890145622193812, 0.20678851008415222, -2.790637969970703, -0.73921799659729, 4782.0, 127.59860229492188, 33.244632720947266predicting for \n",
      "1/1 [==============================] - 0s 15ms/step7266, -0.010511506348848346, 0.2050011157989502, -1.5475680828094482, -1.1493878364562988, 4788.0, 127.66008758544922, 33.3056526184082predicting for \n",
      "1/1 [==============================] - 0s 14ms/step82, 0.07598277181386948, 0.22487881779670715, -2.675590991973877, 1.4060509204864502, 4794.0, 127.74125671386719, 33.36597442626953predicting for \n",
      "1/1 [==============================] - 0s 15ms/step953, 0.09185819327831268, 0.22457191348075867, -1.5653396844863892, 2.4994983673095703, 4800.0, 127.81919860839844, 33.42562484741211predicting for \n",
      "1/1 [==============================] - 0s 15ms/step211, 0.015172526240348816, 0.13885876536369324, -5.673362731933594, -0.0955359935760498, 4806.0, 127.90286254882812, 33.46467590332031predicting for \n",
      "1/1 [==============================] - 0s 15ms/step031, 0.052361877635121346, 0.16969509422779083, -4.836231231689453, -0.3463079929351808, 4812.0, 127.9928970336914, 33.509864807128906predicting for \n",
      "1/1 [==============================] - 0s 14ms/step906, 0.14230549335479736, 0.15590417385101318, -5.8978447914123535, -0.5554540157318115, 4818.0, 128.10829162597656, 33.55210876464844predicting for \n",
      "1/1 [==============================] - 0s 14ms/step844, 0.12706980109214783, 0.17092736065387726, -5.5966644287109375, -1.9199788570404053, 4824.0, 128.2228240966797, 33.59718322753906predicting for \n",
      "1/1 [==============================] - 0s 14ms/step06, 0.11228328198194504, 0.16462759673595428, -6.149451732635498, -2.904792547225952, 4830.0, 128.33892822265625, 33.63993453979492predicting for \n",
      "1/1 [==============================] - 0s 14ms/step492, 0.029543288052082062, 0.13503149151802063, -6.055917263031006, -4.277440071105957, 4836.0, 128.43870544433594, 33.676788330078125predicting for \n",
      "1/1 [==============================] - 0s 14ms/step8125, -0.004256730899214745, 0.16809962689876556, -6.09894323348999, -2.045872926712036, 4842.0, 128.5267791748047, 33.71592712402344predicting for \n",
      "1/1 [==============================] - 0s 17ms/step44, 0.015142216579988599, 0.0945073589682579, -6.231761932373047, -1.9138872623443604, 4848.0, 128.6179962158203, 33.74209213256836predicting for \n",
      "1/1 [==============================] - 0s 13ms/step36, 0.006974969059228897, 0.10046795755624771, -5.836112022399902, -1.5636188983917236, 4854.0, 128.70498657226562, 33.768951416015625predicting for \n",
      "1/1 [==============================] - 0s 15ms/step5625, 0.17291103303432465, 0.14672748744487762, -5.792150974273682, -2.750471353530884, 4860.0, 128.83316040039062, 33.80716323852539predicting for \n",
      "1/1 [==============================] - 0s 16ms/step539, 0.11553623527288437, 0.18409721553325653, -5.496582984924316, -1.0488760471343994, 4866.0, 128.9442138671875, 33.848453521728516predicting for \n",
      "1/1 [==============================] - 0s 14ms/step516, 0.16044116020202637, 0.16028499603271484, -4.8670973777771, -1.8621084690093994, 4872.0, 129.0640869140625, 33.88764190673828predicting for \n",
      "1/1 [==============================] - 0s 14ms/step28, 0.08557160943746567, 0.1456618756055832, -5.465716361999512, -3.111907720565796, 4878.0, 129.17251586914062, 33.922157287597656predicting for \n",
      "1/1 [==============================] - 0s 14ms/step7656, 0.10206237435340881, 0.1369057446718216, -5.392759799957275, -2.6915853023529053, 4884.0, 129.2832489013672, 33.954681396484375predicting for \n",
      "1/1 [==============================] - 0s 14ms/step375, 0.041780631989240646, 0.05956190824508667, -3.4004809856414795, -2.326087713241577, 4890.0, 129.36880493164062, 33.97560119628906predicting for \n",
      "1/1 [==============================] - 0s 14ms/step906, 0.08257012069225311, 0.04580015689134598, -2.641918659210205, -1.4844276905059814, 4896.0, 129.45785522460938, 33.9951057434082predicting for \n",
      "1/1 [==============================] - 0s 14ms/step82, 0.09159427136182785, 0.11355241388082504, -1.663550615310669, -1.6824052333831787, 4902.0, 129.54672241210938, 34.02688217163086predicting for \n",
      "1/1 [==============================] - 0s 14ms/step086, 0.16330812871456146, 0.044304557144641876, 0.46248213946819305, -1.3636102676391602, 4908.0, 129.64002990722656, 34.0511474609375predicting for \n",
      "1/1 [==============================] - 0s 13ms/step75, 0.13993236422538757, 0.0707998275756836, -0.550493448972702, -0.39504098892211914, 4914.0, 129.7308349609375, 34.07659912109375predicting for \n",
      "1/1 [==============================] - 0s 14ms/step75, 0.17836636304855347, 0.07521320134401321, 0.5588223934173584, 2.8873322010040283, 4920.0, 129.8176727294922, 34.10224151611328predicting for \n",
      "1/1 [==============================] - 0s 14ms/step28, 0.15315675735473633, 0.006022083107382059, 0.9853384494781494, 1.996938943862915, 4926.0, 129.89743041992188, 34.117027282714844predicting for \n",
      "1/1 [==============================] - 0s 14ms/step4844, 0.1372648924589157, -0.009804141242057085, 1.1742775440216064, 0.10853362083435059, 4932.0, 129.97674560546875, 34.130435943603516predicting for \n",
      "1/1 [==============================] - 0s 16ms/step3516, 0.12854380905628204, 0.005812713410705328, -0.6730232238769531, 1.8862743377685547, 4938.0, 130.0581817626953, 34.14216995239258predicting for \n",
      "1/1 [==============================] - 0s 14ms/step58, 0.0938965231180191, 0.005009485874325037, 2.2985587120056152, 1.9390685558319092, 4944.0, 130.1182861328125, 34.1567268371582predicting for \n",
      "1/1 [==============================] - 0s 15ms/step2, 0.14025674760341644, -0.009544732864014804, 3.240448236465454, 2.1908559799194336, 4950.0, 130.18360900878906, 34.1707649230957predicting for \n",
      "1/1 [==============================] - 0s 15ms/step57, 0.13947463035583496, -0.05009639263153076, 5.058753490447998, -0.9219670295715332, 4956.0, 130.24693298339844, 34.18269348144531predicting for \n",
      "1/1 [==============================] - 0s 14ms/step531, 0.12191575020551682, -0.004042387008666992, 1.1406052112579346, 2.994951009750366, 4962.0, 130.3154754638672, 34.19369125366211predicting for \n",
      "1/1 [==============================] - 0s 14ms/step11, 0.13659994304180145, 0.06177736818790436, 2.8822121620178223, 3.577716827392578, 4968.0, 130.37966918945312, 34.21698760986328predicting for \n",
      "1/1 [==============================] - 0s 15ms/step328, 0.20996980369091034, 0.038658060133457184, 3.5388224124908447, 2.876164197921753, 4974.0, 130.45848083496094, 34.23950958251953predicting for \n",
      "1/1 [==============================] - 0s 14ms/step953, 0.18677230179309845, -0.006847457028925419, 4.458263874053955, 0.4831688404083252, 4980.0, 130.5325927734375, 34.256675720214844predicting for \n",
      "1/1 [==============================] - 0s 15ms/step844, 0.1523376852273941, 0.11955082416534424, 3.3770081996917725, 3.1452112197875977, 4986.0, 130.6005859375, 34.289337158203125predicting for \n",
      "1/1 [==============================] - 0s 14ms/step, 0.1604882776737213, 0.12982837855815887, 3.284409284591675, 4.456942081451416, 4992.0, 130.66822814941406, 34.32205581665039predicting for \n",
      "1/1 [==============================] - 0s 14ms/step039, 0.15011736750602722, 0.12359389662742615, 1.9927018880844116, 4.389934062957764, 4998.0, 130.73956298828125, 34.3513298034668predicting for \n",
      "1/1 [==============================] - 0s 14ms/step68, 0.15205878019332886, 0.09073343873023987, 4.30299711227417, 0.5755586624145508, 5004.0, 130.8094482421875, 34.380340576171875predicting for \n",
      "1/1 [==============================] - 0s 14ms/step875, 0.11634065210819244, 0.1505012959241867, 2.109619617462158, 2.521834373474121, 5010.0, 130.87815856933594, 34.413429260253906predicting for \n",
      "1/1 [==============================] - 0s 14ms/step3906, 0.08773919194936752, 0.18196505308151245, 0.2277112603187561, 3.731022834777832, 5016.0, 130.9468994140625, 34.44694900512695predicting for \n",
      "1/1 [==============================] - 0s 14ms/step95, 0.08575040847063065, 0.2165527641773224, 0.24922418594360352, 3.552335262298584, 5022.0, 131.01670837402344, 34.48548126220703predicting for \n",
      "result : 5022.0, 131.01670837402344, 34.48548126220703, nan, nan, 3.3723316192626953, 3.0477452278137207, 5028.0, nan, nanEncountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 4 completed.\n",
      "Predicting for index 5...\n",
      "inital value load for index 5...\n",
      "result : 4788.0, 129.29723333333334, 34.92175, 0.2030828446149826, 0.3891388177871704, 1.0723252296447754, 2.255833148956299, 4794.0\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step30828446149826, 0.3891388177871704, 1.0723252296447754, 2.255833148956299, 4794.0, 129.40757751464844, 34.99172592163086predicting for\n",
      "1/1 [==============================] - 0s 14ms/step086, 0.15316049754619598, 0.3795182406902313, -1.5475680828094482, -1.097609043121338, 4800.0, 129.52590942382812, 35.0584831237793predicting for\n",
      "1/1 [==============================] - 0s 14ms/step93, 0.16533829271793365, 0.3661661148071289, -5.188855171203613, -2.728135347366333, 4806.0, 129.66722106933594, 35.118839263916016predicting for\n",
      "1/1 [==============================] - 0s 15ms/step6016, 0.16523541510105133, 0.38160112500190735, -4.6182966232299805, -1.954498052597046, 4812.0, 129.80467224121094, 35.18169021606445predicting for\n",
      "1/1 [==============================] - 0s 16ms/step445, -0.0005199573934078199, 0.11487279087305069, -5.712646961212158, -2.149430513381958, 4818.0, 129.90211486816406, 35.19639205932617predicting for\n",
      "1/1 [==============================] - 0s 14ms/step617, 0.00906024407595396, 0.09213803708553314, -3.754040479660034, -4.925183296203613, 4824.0, 129.9991455078125, 35.212257385253906predicting for\n",
      "1/1 [==============================] - 0s 15ms/step906, -0.010082191787660122, 0.10151845961809158, -5.455427646636963, -4.643952369689941, 4830.0, 130.09857177734375, 35.226898193359375predicting for\n",
      "1/1 [==============================] - 0s 17ms/step9375, -0.08567991107702255, -0.04696638509631157, -4.1833624839782715, -5.769888877868652, 4836.0, 130.1731719970703, 35.220420837402344predicting for\n",
      "1/1 [==============================] - 0s 14ms/step344, -0.07503996044397354, -0.022522207349538803, -5.448880195617676, -3.4906041622161865, 4842.0, 130.2510223388672, 35.2138557434082predicting for\n",
      "1/1 [==============================] - 0s 14ms/step2, -0.052640900015830994, -0.05752626061439514, -4.955019950866699, -3.718024969100952, 4848.0, 130.33172607421875, 35.202247619628906predicting for \n",
      "1/1 [==============================] - 0s 15ms/step8906, -0.04443615674972534, -0.03244922682642937, -4.30776309967041, -2.78397536277771, 4854.0, 130.40966796875, 35.19475173950195predicting for \n",
      "1/1 [==============================] - 0s 15ms/step, -0.051429808139801025, -0.05427360534667969, -4.127242088317871, -4.423639297485352, 4860.0, 130.48822021484375, 35.18537521362305predicting for \n",
      "1/1 [==============================] - 0s 13ms/step305, -0.06976703554391861, -0.0389518216252327, -4.765145301818848, -3.1626713275909424, 4866.0, 130.56228637695312, 35.17655563354492predicting for \n",
      "1/1 [==============================] - 0s 14ms/step492, -0.02307783253490925, 0.054083116352558136, -4.26567268371582, -3.292626142501831, 4872.0, 130.647705078125, 35.183265686035156predicting for \n",
      "1/1 [==============================] - 0s 14ms/step56, -0.05199061334133148, 0.07320456206798553, -4.596783638000488, -4.14748477935791, 4878.0, 130.7298583984375, 35.193424224853516predicting for \n",
      "1/1 [==============================] - 0s 14ms/step516, -0.04234045743942261, 0.07284091413021088, -4.591171741485596, -3.6611697673797607, 4884.0, 130.81304931640625, 35.202850341796875predicting for \n",
      "1/1 [==============================] - 0s 15ms/step6875, 0.005402735318057239, 0.1650795042514801, -6.029727935791016, -3.312931776046753, 4890.0, 130.91537475585938, 35.224700927734375predicting for \n",
      "1/1 [==============================] - 0s 14ms/step4375, 0.03536639083176851, 0.157388374209404, -5.232816219329834, -2.246896505355835, 4896.0, 131.01866149902344, 35.24520492553711predicting for \n",
      "1/1 [==============================] - 0s 14ms/step711, 0.13655516505241394, 0.11766071617603302, -2.8149569034576416, 0.2374732494354248, 4902.0, 131.12843322753906, 35.26060485839844predicting for \n",
      "1/1 [==============================] - 0s 15ms/step844, 0.22422409057617188, 0.01830023154616356, 0.6224256753921509, -1.0509064197540283, 4908.0, 131.24424743652344, 35.266326904296875predicting for \n",
      "1/1 [==============================] - 0s 13ms/step6875, 0.20592930912971497, 0.08070486225187778, -3.800807476043701, 0.10142683982849132, 4914.0, 131.37374877929688, 35.274654388427734predicting for \n",
      "1/1 [==============================] - 0s 14ms/step7734, 0.34928181767463684, -0.001491650938987732, 0.03316009044647217, 6.662112236022949, 4920.0, 131.50157165527344, 35.272857666015625predicting for \n",
      "1/1 [==============================] - 0s 15ms/step5625, 0.33578771352767944, -0.023486321792006486, 3.2498016357421875, 3.7279772758483887, 4926.0, 131.61790466308594, 35.2732048034668predicting for \n",
      "1/1 [==============================] - 0s 14ms/step68, 0.3078829348087311, -0.04352961853146553, 3.3751375675201416, 1.626364827156067, 4932.0, 131.73138427734375, 35.27134704589844predicting for \n",
      "1/1 [==============================] - 0s 17ms/step844, 0.26959773898124695, -0.008035330101847649, -0.2221883088350296, 2.6497585773468018, 4938.0, 131.84996032714844, 35.26887130737305predicting for \n",
      "1/1 [==============================] - 0s 15ms/step305, 0.2704510986804962, 0.08882344514131546, 2.8382511138916016, 6.0427961349487305, 4944.0, 131.94886779785156, 35.28284454345703predicting for \n",
      "1/1 [==============================] - 0s 14ms/step703, 0.30896899104118347, 0.07194358110427856, 2.2415027618408203, 5.290480136871338, 4950.0, 132.06048583984375, 35.29466247558594predicting for \n",
      "1/1 [==============================] - 0s 14ms/step594, 0.26721256971359253, 0.13115276396274567, 5.969776630401611, 3.577716827392578, 4956.0, 132.1509246826172, 35.319183349609375predicting for \n",
      "1/1 [==============================] - 0s 13ms/step375, 0.23187755048274994, 0.15772995352745056, 2.6212518215179443, 4.051848888397217, 4962.0, 132.24778747558594, 35.344078063964844predicting for \n",
      "1/1 [==============================] - 0s 14ms/step4844, 0.2663998007774353, 0.15491856634616852, 3.3882322311401367, 4.565576076507568, 4968.0, 132.3477783203125, 35.36927032470703predicting for \n",
      "1/1 [==============================] - 0s 14ms/step03, 0.3238224685192108, 0.16560713946819305, 5.231791973114014, 4.977776527404785, 4974.0, 132.45187377929688, 35.39836883544922predicting for \n",
      "1/1 [==============================] - 0s 14ms/step922, 0.3215590715408325, 0.1395079344511032, 5.348709583282471, 2.2629401683807373, 4980.0, 132.56065368652344, 35.425296783447266predicting for \n",
      "result : 4980.0, 132.56065368652344, 35.425296783447266, nan, nan, 2.11336088180542, 3.062974214553833, 4986.0, nan, nanEncountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 5 completed.\n",
      "Predicting for index 6...\n",
      "inital value load for index 6...\n",
      "result : 4824.0, 129.39828333333332, 37.55258333333333, 0.025877391919493675, 0.015027848072350025, -3.240537643432617, 1.6537771224975586, 4830.0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step333, 0.025877391919493675, 0.015027848072350025, -3.240537643432617, 1.6537771224975586, 4830.0, 129.48118591308594, 37.54117965698242predicting for\n",
      "1/1 [==============================] - 0s 14ms/step242, -0.003475172445178032, 0.006258685141801834, -3.220895290374756, 1.4385395050048828, 4836.0, 129.55690002441406, 37.52915573120117predicting for\n",
      "1/1 [==============================] - 0s 14ms/step117, 0.14031663537025452, 0.1358553022146225, -4.306827545166016, 1.7278919219970703, 4842.0, 129.67529296875, 37.53799819946289predicting for\n",
      "1/1 [==============================] - 0s 14ms/step, 0.14877410233020782, 0.1370387077331543, -2.1443166732788086, 3.1137378215789795, 4848.0, 129.78298950195312, 37.54926681518555predicting for\n",
      "1/1 [==============================] - 0s 14ms/step555, 0.26797398924827576, 0.2731316089630127, -2.682138204574585, 2.544170379638672, 4854.0, 129.92572021484375, 37.58684158325195predicting for\n",
      "1/1 [==============================] - 0s 14ms/step195, 0.26790714263916016, 0.25947892665863037, -2.5745739936828613, 2.173596143722534, 4860.0, 130.06912231445312, 37.62194061279297predicting for\n",
      "1/1 [==============================] - 0s 15ms/step297, 0.33822494745254517, 0.31763848662376404, -3.69885516166687, 2.392894983291626, 4866.0, 130.23558044433594, 37.66718292236328predicting for\n",
      "1/1 [==============================] - 0s 14ms/step328, 0.3427160978317261, 0.29462847113609314, -2.9954779148101807, 3.0304856300354004, 4872.0, 130.39883422851562, 37.708091735839844predicting for\n",
      "1/1 [==============================] - 0s 14ms/step9844, 0.4039103388786316, 0.2678098976612091, -3.611868381500244, 2.418276786804199, 4878.0, 130.5823974609375, 37.74337387084961predicting for\n",
      "1/1 [==============================] - 0s 14ms/step61, 0.378880113363266, 0.28832730650901794, -3.34623122215271, 3.4772050380706787, 4884.0, 130.75616455078125, 37.78221130371094predicting for \n",
      "1/1 [==============================] - 0s 15ms/step094, 0.28167182207107544, 0.40584465861320496, -4.891416549682617, 1.9735877513885498, 4890.0, 130.91567993164062, 37.8442497253418predicting for \n",
      "1/1 [==============================] - 0s 14ms/step18, 0.2812441885471344, 0.4254736304283142, -4.368560314178467, 4.270132064819336, 4896.0, 131.0675048828125, 37.909339904785156predicting for \n",
      "1/1 [==============================] - 0s 15ms/step156, 0.23759764432907104, 0.2896818220615387, -2.438014030456543, 2.9807372093200684, 4902.0, 131.20249938964844, 37.949459075927734predicting for \n",
      "1/1 [==============================] - 0s 16ms/step7734, 0.22136619687080383, 0.2877887487411499, -2.6624960899353027, 1.988816738128662, 4908.0, 131.33682250976562, 37.98957443237305predicting for \n",
      "1/1 [==============================] - 0s 14ms/step305, 0.06324561685323715, 0.0455438606441021, -3.575390100479126, 1.6060594320297241, 4914.0, 131.4345245361328, 37.98194122314453predicting for \n",
      "1/1 [==============================] - 0s 14ms/step53, 0.08934562653303146, 0.02256709337234497, -0.8778631687164307, 3.987886667251587, 4920.0, 131.52127075195312, 37.97224426269531predicting for \n",
      "1/1 [==============================] - 0s 14ms/step531, -0.04826602339744568, -0.21553409099578857, -2.611987590789795, 0.13594603538513184, 4926.0, 131.5878143310547, 37.92138671875predicting for \n",
      "1/1 [==============================] - 0s 14ms/step -0.051425740122795105, -0.20669595897197723, -3.0104434490203857, 2.2923829555511475, 4932.0, 131.650390625, 37.87013244628906predicting for \n",
      "1/1 [==============================] - 0s 14ms/step-0.05128917843103409, -0.17120201885700226, -2.712069272994995, 3.0822644233703613, 4938.0, 131.71006774902344, 37.8253288269043predicting for \n",
      "1/1 [==============================] - 0s 14ms/step43, -0.05827545374631882, -0.1678743064403534, -1.5185725688934326, 3.8853442668914795, 4944.0, 131.7606658935547, 37.782814025878906predicting for \n",
      "1/1 [==============================] - 0s 15ms/step906, -0.08024576306343079, -0.31743931770324707, 1.433367371559143, 1.9918625354766846, 4950.0, 131.7960205078125, 37.721046447753906predicting for \n",
      "1/1 [==============================] - 0s 14ms/step906, -0.24049602448940277, -0.27242228388786316, 3.1712329387664795, -1.0600440502166748, 4956.0, 131.78834533691406, 37.67599868774414predicting for \n",
      "1/1 [==============================] - 0s 14ms/step414, -0.23108640313148499, -0.24792277812957764, 0.4400339722633361, -0.16660499572753917, 4962.0, 131.79364013671875, 37.63116455078125predicting for \n",
      "1/1 [==============================] - 0s 15ms/step125, -0.20657847821712494, -0.24469488859176636, 3.728696823120117, 1.1887826919555664, 4968.0, 131.78741455078125, 37.58879852294922predicting for \n",
      "1/1 [==============================] - 0s 14ms/step922, -0.21998412907123566, -0.2285463660955429, -0.005188941955566406, 1.1613703966140747, 4974.0, 131.7947540283203, 37.545509338378906predicting for \n",
      "1/1 [==============================] - 0s 15ms/step906, -0.1852118819952011, -0.22692638635635376, 1.4969706535339355, 3.156379222869873, 4980.0, 131.79998779296875, 37.502254486083984predicting for \n",
      "1/1 [==============================] - 0s 15ms/step3984, -0.17427293956279755, -0.22944007813930511, 1.1518293619155884, 3.015256404876709, 4986.0, 131.81008911132812, 37.457977294921875predicting for \n",
      "1/1 [==============================] - 0s 14ms/step1875, -0.05036666616797447, -0.1350473016500473, 3.6379687786102295, 5.570694923400879, 4992.0, 131.8360137939453, 37.42778015136719predicting for \n",
      "1/1 [==============================] - 0s 13ms/step19, -0.03631360083818436, -0.13613514602184296, 4.0261359214782715, 6.182904243469238, 4998.0, 131.86239624023438, 37.39685821533203predicting for \n",
      "1/1 [==============================] - 0s 15ms/step203, -0.024214737117290497, -0.14049284160137177, 4.887585639953613, 6.139246940612793, 5004.0, 131.88812255859375, 37.36481475830078predicting for \n",
      "1/1 [==============================] - 0s 14ms/step078, -0.011514057405292988, -0.11843863129615784, 3.6445159912109375, 7.12913703918457, 5010.0, 131.92059326171875, 37.33604431152344predicting for \n",
      "1/1 [==============================] - 0s 14ms/step344, 0.02699531614780426, -0.13089528679847717, 5.822927951812744, 7.271275520324707, 5016.0, 131.95277404785156, 37.303245544433594predicting for \n",
      "1/1 [==============================] - 0s 14ms/step3594, 0.011031805537641048, -0.1301002949476242, 4.436750888824463, 8.061156272888184, 5022.0, 131.98526000976562, 37.27134704589844predicting for \n",
      "1/1 [==============================] - 0s 13ms/step844, 0.0032825153321027756, -0.12367314100265503, 4.4423627853393555, 8.20329475402832, 5028.0, 132.01547241210938, 37.24046325683594predicting for \n",
      "1/1 [==============================] - 0s 14ms/step594, 0.2290675938129425, 0.10989156365394592, 2.4818856716156006, 7.7951555252075195, 5034.0, 132.11444091796875, 37.251991271972656predicting for \n",
      "1/1 [==============================] - 0s 16ms/step2656, 0.07423508167266846, 0.05632622912526131, 4.690228462219238, 8.73123550415039, 5040.0, 132.16177368164062, 37.25249481201172predicting for \n",
      "1/1 [==============================] - 0s 14ms/step172, 0.05233189836144447, 0.02609752118587494, 4.500354290008545, 5.928071022033691, 5046.0, 132.21099853515625, 37.24945068359375predicting for \n",
      "1/1 [==============================] - 0s 13ms/step375, 0.17654867470264435, 0.057252563536167145, 4.974572658538818, 4.2193684577941895, 5052.0, 132.29379272460938, 37.253265380859375predicting for \n",
      "1/1 [==============================] - 0s 14ms/step9375, 0.04375854507088661, 0.08922649174928665, 2.921496629714966, 4.095505714416504, 5058.0, 132.3529815673828, 37.262821197509766predicting for \n",
      "1/1 [==============================] - 0s 14ms/step766, 0.040188904851675034, 0.08842843025922775, 3.5070207118988037, 6.359560966491699, 5064.0, 132.40309143066406, 37.270877838134766predicting for \n",
      "1/1 [==============================] - 0s 14ms/step4766, 0.05273494869470596, 0.06908934563398361, 4.445168972015381, 4.174696922302246, 5070.0, 132.45730590820312, 37.2767448425293predicting for \n",
      "1/1 [==============================] - 0s 14ms/step93, 0.007348854094743729, 0.06464671343564987, 3.7651753425598145, 2.013183355331421, 5076.0, 132.50820922851562, 37.28382110595703predicting for \n",
      "1/1 [==============================] - 0s 18ms/step703, -0.007267057429999113, 0.31539416313171387, 0.13230639696121216, 1.5887997150421143, 5082.0, 132.5746612548828, 37.33626174926758predicting for \n",
      "1/1 [==============================] - 0s 14ms/step58, 0.004021845641545951, 0.3151566982269287, 1.7083579301834106, 2.2883219718933105, 5088.0, 132.63525390625, 37.3900146484375predicting for \n",
      "1/1 [==============================] - 0s 13ms/step -0.006616421043872833, 0.30853956937789917, -0.0491500049829483, -0.550377607345581, 5094.0, 132.7076416015625, 37.442447662353516predicting for \n",
      "1/1 [==============================] - 0s 15ms/step516, -0.02320943772792816, 0.31796449422836304, 0.3857840895652771, 1.1512176990509033, 5100.0, 132.76974487304688, 37.49653625488281predicting for \n",
      "1/1 [==============================] - 0s 14ms/step281, 0.01192418485879898, 0.5554339289665222, -0.813324511051178, -1.0092804431915283, 5106.0, 132.85232543945312, 37.599857330322266predicting for \n",
      "1/1 [==============================] - 0s 14ms/step2266, 0.0344715341925621, 0.510043740272522, -0.7366265058517456, 0.32174086570739746, 5112.0, 132.93682861328125, 37.69244384765625predicting for \n",
      "1/1 [==============================] - 0s 15ms/step625, 0.02754897251725197, 0.511017918586731, -1.631748914718628, 0.17757225036621094, 5118.0, 133.02374267578125, 37.784141540527344predicting for \n",
      "1/1 [==============================] - 0s 14ms/step7344, 0.22533167898654938, 0.3792431950569153, -0.14174887537956238, -1.0194330215454102, 5124.0, 133.15721130371094, 37.84947967529297predicting for \n",
      "1/1 [==============================] - 0s 13ms/step297, 0.20131337642669678, 0.4012185037136078, -1.711253046989441, -1.025524616241455, 5130.0, 133.29159545898438, 37.91691970825195predicting for \n",
      "1/1 [==============================] - 0s 13ms/step195, 0.27320411801338196, 0.21546974778175354, 0.4269391596317291, 0.8192238807678223, 5136.0, 133.42962646484375, 37.948795318603516predicting for \n",
      "1/1 [==============================] - 0s 14ms/step3516, 0.2669658362865448, 0.18097271025180817, -0.36248964071273804, -2.3331944942474365, 5142.0, 133.57693481445312, 37.97489547729492predicting for \n",
      "1/1 [==============================] - 0s 14ms/step492, 0.1927466243505478, 0.027288174256682396, -0.11088258028030396, -1.952467679977417, 5148.0, 133.7022705078125, 37.971527099609375predicting for \n",
      "1/1 [==============================] - 0s 14ms/step375, 0.21279868483543396, 0.060343679040670395, -2.5268714427948, -0.7524166107177734, 5154.0, 133.8406982421875, 37.96989822387695predicting for \n",
      "1/1 [==============================] - 0s 14ms/step95, 0.12787315249443054, -0.028047085274010897, 0.3305988907814026, 0.5907876491546631, 5160.0, 133.9407501220703, 37.95518112182617predicting for \n",
      "1/1 [==============================] - 0s 14ms/step17, 0.08456037193536758, -0.029482336714863777, -3.391127586364746, 0.0425410270690918, 5166.0, 134.0474090576172, 37.93505096435547predicting for \n",
      "1/1 [==============================] - 0s 15ms/step47, -0.0060866475105285645, -0.0680653303861618, -1.2099095582962036, 0.5461158752441406, 5172.0, 134.11917114257812, 37.91162872314453predicting for \n",
      "1/1 [==============================] - 0s 14ms/step453, -0.0024732434540055692, -0.06246425583958626, -0.4541531801223755, -0.28742218017578125, 5178.0, 134.1905059814453, 37.89093780517578predicting for \n",
      "1/1 [==============================] - 0s 14ms/step78, 0.0017788615077733994, -0.05462947115302086, -0.6103552579879761, 0.893338680267334, 5184.0, 134.2608184814453, 37.87042999267578predicting for \n",
      "1/1 [==============================] - 0s 16ms/step78, -0.0998934879899025, -0.13908062875270844, -1.0462247133255005, -0.09756636619567871, 5190.0, 134.3080291748047, 37.8362922668457predicting for \n",
      "1/1 [==============================] - 0s 15ms/step7, -0.0945555791258812, -0.14342224597930908, -0.17074447870254517, -0.6884546279907227, 5196.0, 134.3539581298828, 37.803157806396484predicting for \n",
      "1/1 [==============================] - 0s 14ms/step484, -0.10730022192001343, -0.13606832921504974, -1.2239397764205933, -1.1585252285003662, 5202.0, 134.40219116210938, 37.770267486572266predicting for \n",
      "1/1 [==============================] - 0s 14ms/step2266, -0.07494819164276123, -0.13268056511878967, 0.013517916202545166, 0.8862317800521851, 5208.0, 134.44839477539062, 37.73769760131836predicting for \n",
      "1/1 [==============================] - 0s 14ms/step836, -0.09198659658432007, -0.18609914183616638, 0.6635807156562805, 0.3806264400482178, 5214.0, 134.48728942871094, 37.698150634765625predicting for \n",
      "1/1 [==============================] - 0s 14ms/step5625, -0.09071572124958038, -0.16401407122612, -0.8348374366760254, 0.04964804649353027, 5220.0, 134.53402709960938, 37.660179138183594predicting for \n",
      "1/1 [==============================] - 0s 14ms/step3594, -0.10878066718578339, -0.2102060467004776, -2.461397647857666, -1.658038854598999, 5226.0, 134.58609008789062, 37.61409378051758predicting for \n",
      "1/1 [==============================] - 0s 14ms/step758, -0.08315284550189972, -0.18067802488803864, -2.0807132720947266, 1.7806861400604248, 5232.0, 134.63525390625, 37.57012939453125predicting for \n",
      "1/1 [==============================] - 0s 14ms/step, -0.10775160044431686, -0.2038644701242447, -2.939357280731201, 0.07706022262573231, 5238.0, 134.68507385253906, 37.522953033447266predicting for \n",
      "1/1 [==============================] - 0s 16ms/step7266, -0.10952315479516983, -0.1800689995288849, -3.6015796661376953, -1.0163872241973877, 5244.0, 134.74009704589844, 37.47943878173828predicting for \n",
      "1/1 [==============================] - 0s 14ms/step828, -0.1305762231349945, -0.15864266455173492, -4.54440450668335, -0.413316011428833, 5250.0, 134.79258728027344, 37.43770217895508predicting for \n",
      "1/1 [==============================] - 0s 14ms/step508, -0.10390094667673111, -0.13926146924495697, -2.943098783493042, 1.0172017812728882, 5256.0, 134.84149169921875, 37.39991760253906predicting for \n",
      "1/1 [==============================] - 0s 15ms/step906, -0.09857957065105438, -0.12966139614582062, -2.8589179515838623, 0.9105982780456543, 5262.0, 134.8915252685547, 37.363773345947266predicting for \n",
      "1/1 [==============================] - 0s 14ms/step266, -0.07327722012996674, -0.16666552424430847, 0.09208667278289795, 1.1055305004119873, 5268.0, 134.93328857421875, 37.32571029663086predicting for \n",
      "1/1 [==============================] - 0s 14ms/step086, -0.10479337722063065, -0.16840168833732605, -0.07814562320709234, -1.6133668422698975, 5274.0, 134.97384643554688, 37.28953552246094predicting for \n",
      "1/1 [==============================] - 0s 14ms/step094, -0.09974092990159988, -0.14914390444755554, -1.8412655591964722, 0.32174086570739746, 5280.0, 135.01893615722656, 37.25220489501953predicting for \n",
      "1/1 [==============================] - 0s 13ms/step953, -0.07099716365337372, -0.11381712555885315, 0.049060940742492676, -3.5322306156158447, 5286.0, 135.07264709472656, 37.225799560546875predicting for \n",
      "1/1 [==============================] - 0s 14ms/step6875, -0.11119439452886581, -0.07110018283128738, 0.3259221911430359, -5.832836151123047, 5292.0, 135.1211700439453, 37.208648681640625predicting for \n",
      "1/1 [==============================] - 0s 16ms/step625, -0.12605275213718414, -0.07271743565797806, -0.45134711265563965, -4.836853981018066, 5298.0, 135.16650390625, 37.18974685668945predicting for \n",
      "1/1 [==============================] - 0s 14ms/step, -0.09885677695274353, -0.1215151771903038, 1.6484960317611694, -6.401388168334961, 5304.0, 135.21217346191406, 37.166046142578125predicting for \n",
      "1/1 [==============================] - 0s 15ms/step8125, -0.08674792945384979, -0.16649386286735535, 1.7476422786712646, -5.804408073425293, 5310.0, 135.25758361816406, 37.13483810424805predicting for \n",
      "1/1 [==============================] - 0s 15ms/step805, -0.12833082675933838, -0.048934079706668854, -0.7787168622016907, -5.652117729187012, 5316.0, 135.3052978515625, 37.11980056762695predicting for \n",
      "1/1 [==============================] - 0s 15ms/step95, -0.12947162985801697, -0.02492939308285713, -0.9367896914482117, -4.3474931716918945, 5322.0, 135.3506317138672, 37.107242584228516predicting for \n",
      "1/1 [==============================] - 0s 15ms/step516, -0.09299172461032867, -0.028976330533623695, -0.2829855680465698, -3.790109395980835, 5328.0, 135.40069580078125, 37.0938606262207predicting for \n",
      "1/1 [==============================] - 0s 14ms/step07, -0.08198963105678558, -0.0027303546667099, -0.4943728446960449, -1.6377336978912354, 5334.0, 135.44967651367188, 37.082523345947266predicting for \n",
      "1/1 [==============================] - 0s 14ms/step7266, -0.07782362401485443, -0.003999395878054202, -0.7431738972663879, -3.539337396621704, 5340.0, 135.5050048828125, 37.07200622558594predicting for \n",
      "1/1 [==============================] - 0s 14ms/step94, -0.11440285295248032, 0.09575735032558441, -1.56721031665802, -2.8438761234283447, 5346.0, 135.55528259277344, 37.076416015625predicting for \n",
      "1/1 [==============================] - 0s 14ms/step5, -0.09694275259971619, 0.09952802211046219, -2.3856348991394043, -2.074300527572632, 5352.0, 135.61172485351562, 37.07929229736328predicting for \n",
      "1/1 [==============================] - 0s 15ms/step328, -0.0953340232372284, 0.09579046070575714, -2.9019436836242676, -1.7961161136627197, 5358.0, 135.66990661621094, 37.080387115478516predicting for \n",
      "1/1 [==============================] - 0s 14ms/step8516, -0.11832436919212341, 0.08688011765480042, -3.280757188796997, -3.895697832107544, 5364.0, 135.72850036621094, 37.0813102722168predicting for \n",
      "1/1 [==============================] - 0s 14ms/step68, -0.13799236714839935, 0.0999012216925621, -4.351724147796631, -3.1667325496673584, 5370.0, 135.78526306152344, 37.0822639465332predicting for \n",
      "1/1 [==============================] - 0s 18ms/step32, -0.10140663385391235, 0.20407529175281525, -5.451686382293701, -1.7108328342437744, 5376.0, 135.85508728027344, 37.09724807739258predicting for \n",
      "1/1 [==============================] - 0s 14ms/step258, -0.03343047946691513, 0.2143971472978592, -3.197511911392212, 0.33493924140930176, 5382.0, 135.9272003173828, 37.114925384521484predicting for \n",
      "1/1 [==============================] - 0s 13ms/step484, -0.04837074503302574, 0.1759280562400818, -2.3080015182495117, -2.1078040599823, 5388.0, 135.996337890625, 37.129302978515625predicting for \n",
      "1/1 [==============================] - 0s 14ms/step25, -0.05245940014719963, 0.2303960621356964, -4.552822589874268, -0.5178887844085693, 5394.0, 136.0718536376953, 37.148155212402344predicting for \n",
      "1/1 [==============================] - 0s 15ms/step344, 0.060981828719377525, 0.35326477885246277, 0.4942837953567505, 3.3959832191467285, 5400.0, 136.146728515625, 37.19207763671875predicting for \n",
      "1/1 [==============================] - 0s 14ms/step5, 0.1422635167837143, 0.37325504422187805, 2.6493120193481445, 5.99609375, 5406.0, 136.22586059570312, 37.2408447265625predicting for \n",
      "1/1 [==============================] - 0s 15ms/step25, 0.11582718044519424, 0.34369027614593506, 3.683800458908081, 1.8527703285217285, 5412.0, 136.30345153808594, 37.28781509399414predicting for \n",
      "1/1 [==============================] - 0s 13ms/step414, -0.08150124549865723, 0.42648717761039734, -2.336061716079712, 0.37859606742858887, 5418.0, 136.3636932373047, 37.344886779785156predicting for \n",
      "1/1 [==============================] - 0s 14ms/step156, -0.0378568209707737, 0.38102176785469055, 1.1181570291519165, 1.8080984354019165, 5424.0, 136.41555786132812, 37.39662170410156predicting for 1\n",
      "1/1 [==============================] - 0s 15ms/step156, -0.020111549645662308, 0.38442176580429077, 2.6773722171783447, 1.03243088722229, 5430.0, 136.46685791015625, 37.45142364501953predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step953, -0.03513201232999563, 0.3738273084163666, 1.9169392585754395, -1.6113364696502686, 5436.0, 136.524169921875, 37.505558013916016predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step16, 0.035663485527038574, 0.17789410054683685, -1.1547244787216187, 0.16843461990356445, 5442.0, 136.6046142578125, 37.51883316040039predicting for 1\n",
      "1/1 [==============================] - 0s 13ms/step39, 0.0711672380566597, 0.16506405174732208, 2.302299976348877, 2.2527873516082764, 5448.0, 136.67318725585938, 37.53269577026367predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step367, 0.09415947645902634, 0.17692896723747253, -1.5905938148498535, -3.2459237575531006, 5454.0, 136.77780151367188, 37.547733306884766predicting for 1\n",
      "1/1 [==============================] - 0s 13ms/step4766, 0.20058517158031464, 0.039112042635679245, 2.971069812774658, 1.5075780153274536, 5460.0, 136.87351989746094, 37.54303741455078predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step078, 0.12874270975589752, 0.09157485514879227, -2.3734753131866455, 1.9187630414962769, 5466.0, 136.9750518798828, 37.538265228271484predicting for 1\n",
      "1/1 [==============================] - 0s 13ms/step484, 0.13864827156066895, 0.07893278449773788, -0.7272730469703674, 1.6456549167633057, 5472.0, 137.07154846191406, 37.53392791748047predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step047, 0.17214438319206238, 0.02928372286260128, -1.6981582641601562, 0.2902672290802002, 5478.0, 137.18202209472656, 37.521366119384766predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step4766, 0.1061297208070755, -0.0068761068396270275, -0.3503301739692688, -4.94853401184082, 5484.0, 137.28123474121094, 37.5081672668457predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step57, 0.05447680130600929, -0.0401945486664772, -5.167342662811279, -7.237971305847168, 5490.0, 137.39268493652344, 37.484107971191406predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step1406, -0.11867666244506836, -0.15267649292945862, -1.7664382457733154, -6.483624458312988, 5496.0, 137.4403839111328, 37.44709014892578predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step78, -0.04454111307859421, -0.2028750628232956, 3.533210277557373, -5.25108528137207, 5502.0, 137.47872924804688, 37.40751647949219predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step219, -0.05095808580517769, -0.18807236850261688, 3.6781883239746094, -4.090629577636719, 5508.0, 137.5117950439453, 37.36941909790039predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step39, -0.12459393590688705, -0.06227527931332588, -2.2631049156188965, -2.8844869136810303, 5514.0, 137.55245971679688, 37.34209060668945predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step945, -0.14483632147312164, -0.05666536092758179, -3.4425714015960693, -1.8022077083587646, 5520.0, 137.59039306640625, 37.31296920776367predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step367, -0.18023927509784698, -0.05875726789236069, -4.943795680999756, -4.049003601074219, 5526.0, 137.6307830810547, 37.28331756591797predicting for 1\n",
      "1/1 [==============================] - 0s 13ms/step97, -0.17146921157836914, -0.08790764957666397, -3.8372857570648193, -5.278497695922852, 5532.0, 137.6700897216797, 37.25156021118164predicting for 1\n",
      "1/1 [==============================] - 0s 14ms/step64, -0.22900305688381195, -0.06200236827135086, -5.429238319396973, -5.743492126464844, 5538.0, 137.70321655273438, 37.222434997558594predicting for 1\n",
      "result : 5538.0, 137.70321655273438, 37.222434997558594, nan, nan, -1.1229227781295776, -1.7646424770355225, 5544.0, nan, nanEncountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 6 completed.\n"
     ]
    }
   ],
   "source": [
    "# 각 시작 지점에서의 100일간 예측\n",
    "predict_duration = 400  # 100일 * 4 (하루에 6시간 단위로 4번 예측)\n",
    "\n",
    "# 예측 결과를 저장할 DataFrame\n",
    "predictions_df = pd.DataFrame(columns=['time', 'lons', 'lats', 'uo', 'vo', 'u10', 'v10', 'next_time', 'next_lons', 'next_lats'])\n",
    "\n",
    "# .nc 파일 읽기\n",
    "dataset_sea = xr.open_dataset('interpolated_sea_16.nc', engine='netcdf4')\n",
    "dataset_wind = xr.open_dataset('interpolated_wind_16.nc', engine='netcdf4')\n",
    "\n",
    "# 각 시작 지점 별로 for loop\n",
    "for index, row in result_df.iterrows():\n",
    "    print(f\"Predicting for index {index}...\")\n",
    "\n",
    "    # 초기값 불러오기\n",
    "    current_time = row['time']\n",
    "    current_lon = row['lons']\n",
    "    current_lat = row['lats']\n",
    "    uo_value = row['uo']\n",
    "    vo_value = row['vo']\n",
    "    u10_value = row['u10']\n",
    "    v10_value = row['v10']\n",
    "    next_time = row['next_time']\n",
    "    print(f\"inital value load for index {index}...\")\n",
    "    print(f\"result : {current_time}, {current_lon}, {current_lat}, {uo_value}, {vo_value}, {u10_value}, {v10_value}, {next_time}\")\n",
    "    predictions_list = []\n",
    "\n",
    "    # 100일간 예측\n",
    "    for _ in range(predict_duration):\n",
    "        print(f\"predicting for {_}\", end=\"\")\n",
    "        # 모델에 입력값을 넣어 다음 위치를 예측합니다.\n",
    "        input_data = np.array([[current_lon, current_lat, uo_value, vo_value, u10_value, v10_value]])\n",
    "        input_data = input_data.reshape((input_data.shape[0], input_data.shape[1], 1))\n",
    "        prediction = model.predict(input_data)\n",
    "        \n",
    "        # 예측된 위치를 업데이트\n",
    "        predicted_lon = prediction[0][0]\n",
    "        predicted_lat = prediction[0][1]\n",
    "\n",
    "        print(f\"result : {current_time}, {current_lon}, {current_lat}, {uo_value}, {vo_value}, {u10_value}, {v10_value}, {next_time}, {predicted_lon}, {predicted_lat}\", end=\"\")\n",
    "\n",
    "        # 값 중에 nan이 있는지 확인\n",
    "        values_to_check = [current_time, current_lon, current_lat, uo_value, vo_value, u10_value, v10_value, next_time, predicted_lon, predicted_lat]\n",
    "        if any(np.isnan(value) for value in values_to_check):\n",
    "            print(\"Encountered a NaN value. Stopping the prediction loop.\")\n",
    "            break\n",
    "\n",
    "        predictions_list.append({\n",
    "            'time': current_time,\n",
    "            'lons': current_lon,\n",
    "            'lats': current_lat,\n",
    "            'uo': uo_value,\n",
    "            'vo': vo_value,\n",
    "            'u10': u10_value,\n",
    "            'v10': v10_value,\n",
    "            'next_time': next_time,\n",
    "            'next_lons': predicted_lon,\n",
    "            'next_lats': predicted_lat\n",
    "        })\n",
    "\n",
    "        \n",
    "        # 다음 반복을 위한 현재 위치와 시간 업데이트\n",
    "        current_lon = predicted_lon\n",
    "        current_lat = predicted_lat\n",
    "        current_time += 6 # 6시간 뒤로 이동\n",
    "        next_time += 6 # 6시간 뒤로 이동\n",
    "        \n",
    "        # 위도 경도 값을 가져오기 위한 시간 변환\n",
    "        base_dt = datetime(2016, 1, 1, 0, 0)\n",
    "        search_time = np.datetime64(base_dt + timedelta(hours=current_time))\n",
    "\n",
    "        # 현재 위치와 시간을 기반으로 uo, vo, u10, v10 값을 가져옵니다.\n",
    "        uo_value = dataset_sea['uo'].sel(time=search_time, longitude=current_lon, latitude=current_lat, method='nearest').item()\n",
    "        vo_value = dataset_sea['vo'].sel(time=search_time, longitude=current_lon, latitude=current_lat, method='nearest').item()\n",
    "        u10_value = dataset_wind['u10'].sel(time=search_time, longitude=current_lon, latitude=current_lat, method='nearest').item()\n",
    "        v10_value = dataset_wind['v10'].sel(time=search_time, longitude=current_lon, latitude=current_lat, method='nearest').item()\n",
    "    # 리스트를 DataFrame으로 변환\n",
    "    predictions_df = pd.DataFrame(predictions_list)\n",
    "    predictions_df.to_csv(f\"predictions_{index}.csv\", index=False)\n",
    "    print(f\"Predictions for index {index} completed.\")\n",
    "\n",
    "dataset_sea.close()\n",
    "dataset_wind.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
