{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 64)                16896     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17026 (66.51 KB)\n",
      "Trainable params: 17026 (66.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 1329.8724\n",
      "Epoch 1: val_loss improved from inf to 1.87762, saving model to best_model.h5\n",
      "144/144 [==============================] - 3s 11ms/step - loss: 1295.9352 - val_loss: 1.8776\n",
      "Epoch 2/100\n",
      " 17/144 [==>...........................] - ETA: 0s - loss: 1.8798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\in_q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/144 [===========================>..] - ETA: 0s - loss: 1.8606\n",
      "Epoch 2: val_loss improved from 1.87762 to 1.76271, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 1.8524 - val_loss: 1.7627\n",
      "Epoch 3/100\n",
      "143/144 [============================>.] - ETA: 0s - loss: 1.7315\n",
      "Epoch 3: val_loss improved from 1.76271 to 1.62605, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 1.7300 - val_loss: 1.6261\n",
      "Epoch 4/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 1.5900\n",
      "Epoch 4: val_loss improved from 1.62605 to 1.48790, saving model to best_model.h5\n",
      "144/144 [==============================] - 2s 10ms/step - loss: 1.5840 - val_loss: 1.4879\n",
      "Epoch 5/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 1.4683\n",
      "Epoch 5: val_loss improved from 1.48790 to 1.33893, saving model to best_model.h5\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.4600 - val_loss: 1.3389\n",
      "Epoch 6/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 1.3078\n",
      "Epoch 6: val_loss improved from 1.33893 to 1.16897, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 1.3007 - val_loss: 1.1690\n",
      "Epoch 7/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 1.0373\n",
      "Epoch 7: val_loss improved from 1.16897 to 0.79830, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 1.0298 - val_loss: 0.7983\n",
      "Epoch 8/100\n",
      "141/144 [============================>.] - ETA: 0s - loss: 0.5447\n",
      "Epoch 8: val_loss improved from 0.79830 to 0.25730, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.5395 - val_loss: 0.2573\n",
      "Epoch 9/100\n",
      "143/144 [============================>.] - ETA: 0s - loss: 0.1263\n",
      "Epoch 9: val_loss improved from 0.25730 to 0.04556, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.1259 - val_loss: 0.0456\n",
      "Epoch 10/100\n",
      "142/144 [============================>.] - ETA: 0s - loss: 0.0375\n",
      "Epoch 10: val_loss improved from 0.04556 to 0.02702, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0373 - val_loss: 0.0270\n",
      "Epoch 11/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0265\n",
      "Epoch 11: val_loss improved from 0.02702 to 0.01949, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0266 - val_loss: 0.0195\n",
      "Epoch 12/100\n",
      "142/144 [============================>.] - ETA: 0s - loss: 0.0203\n",
      "Epoch 12: val_loss improved from 0.01949 to 0.01831, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0203 - val_loss: 0.0183\n",
      "Epoch 13/100\n",
      "142/144 [============================>.] - ETA: 0s - loss: 0.0186\n",
      "Epoch 13: val_loss did not improve from 0.01831\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0187 - val_loss: 0.0317\n",
      "Epoch 14/100\n",
      "142/144 [============================>.] - ETA: 0s - loss: 0.0155\n",
      "Epoch 14: val_loss did not improve from 0.01831\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0155 - val_loss: 0.0188\n",
      "Epoch 15/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0143\n",
      "Epoch 15: val_loss did not improve from 0.01831\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0145 - val_loss: 0.0192\n",
      "Epoch 16/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 0.0137\n",
      "Epoch 16: val_loss improved from 0.01831 to 0.01279, saving model to best_model.h5\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 17/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0111\n",
      "Epoch 17: val_loss improved from 0.01279 to 0.00875, saving model to best_model.h5\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 18/100\n",
      "143/144 [============================>.] - ETA: 0s - loss: 0.0115\n",
      "Epoch 18: val_loss improved from 0.00875 to 0.00786, saving model to best_model.h5\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.0116 - val_loss: 0.0079\n",
      "Epoch 19/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 0.0098\n",
      "Epoch 19: val_loss improved from 0.00786 to 0.00770, saving model to best_model.h5\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0077\n",
      "Epoch 20/100\n",
      "142/144 [============================>.] - ETA: 0s - loss: 0.0083\n",
      "Epoch 20: val_loss did not improve from 0.00770\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 21/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0090\n",
      "Epoch 21: val_loss improved from 0.00770 to 0.00545, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 22/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0075\n",
      "Epoch 22: val_loss did not improve from 0.00545\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.0074 - val_loss: 0.0087\n",
      "Epoch 23/100\n",
      "142/144 [============================>.] - ETA: 0s - loss: 0.0065\n",
      "Epoch 23: val_loss did not improve from 0.00545\n",
      "144/144 [==============================] - 2s 10ms/step - loss: 0.0065 - val_loss: 0.0103\n",
      "Epoch 24/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0063\n",
      "Epoch 24: val_loss improved from 0.00545 to 0.00487, saving model to best_model.h5\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 25/100\n",
      "141/144 [============================>.] - ETA: 0s - loss: 0.0061\n",
      "Epoch 25: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 26: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 27/100\n",
      "136/144 [===========================>..] - ETA: 0s - loss: 0.0066\n",
      "Epoch 27: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 28/100\n",
      "143/144 [============================>.] - ETA: 0s - loss: 0.0068\n",
      "Epoch 28: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 29/100\n",
      "137/144 [===========================>..] - ETA: 0s - loss: 0.0107\n",
      "Epoch 29: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0108 - val_loss: 0.0205\n",
      "Epoch 30/100\n",
      "138/144 [===========================>..] - ETA: 0s - loss: 0.0080\n",
      "Epoch 30: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 31/100\n",
      "143/144 [============================>.] - ETA: 0s - loss: 0.0100\n",
      "Epoch 31: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0101 - val_loss: 0.0078\n",
      "Epoch 32/100\n",
      "142/144 [============================>.] - ETA: 0s - loss: 0.0122\n",
      "Epoch 32: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0123 - val_loss: 0.0055\n",
      "Epoch 33/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0100\n",
      "Epoch 33: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0101 - val_loss: 0.0137\n",
      "Epoch 34/100\n",
      "143/144 [============================>.] - ETA: 0s - loss: 0.0142\n",
      "Epoch 34: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0142 - val_loss: 0.0095\n",
      "Epoch 35/100\n",
      "138/144 [===========================>..] - ETA: 0s - loss: 0.0212\n",
      "Epoch 35: val_loss did not improve from 0.00487\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0209 - val_loss: 0.0261\n",
      "Epoch 36/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0194\n",
      "Epoch 36: val_loss improved from 0.00487 to 0.00465, saving model to best_model.h5\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0193 - val_loss: 0.0047\n",
      "Epoch 37/100\n",
      "142/144 [============================>.] - ETA: 0s - loss: 0.0323\n",
      "Epoch 37: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0320 - val_loss: 0.0073\n",
      "Epoch 38/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 0.0655\n",
      "Epoch 38: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0647 - val_loss: 0.0221\n",
      "Epoch 39/100\n",
      "143/144 [============================>.] - ETA: 0s - loss: 0.0521\n",
      "Epoch 39: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0520 - val_loss: 0.0365\n",
      "Epoch 40/100\n",
      "136/144 [===========================>..] - ETA: 0s - loss: 0.0740\n",
      "Epoch 40: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0713 - val_loss: 0.0196\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - ETA: 0s - loss: 0.0656\n",
      "Epoch 41: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0656 - val_loss: 0.0964\n",
      "Epoch 42/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0587\n",
      "Epoch 42: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0580 - val_loss: 0.0214\n",
      "Epoch 43/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 0.0717\n",
      "Epoch 43: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0696 - val_loss: 0.0167\n",
      "Epoch 44/100\n",
      "138/144 [===========================>..] - ETA: 0s - loss: 0.0838\n",
      "Epoch 44: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 8ms/step - loss: 0.0815 - val_loss: 0.0249\n",
      "Epoch 45/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 0.0527\n",
      "Epoch 45: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0737 - val_loss: 0.5504\n",
      "Epoch 46/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0476\n",
      "Epoch 46: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0467 - val_loss: 0.0167\n",
      "Epoch 47/100\n",
      "141/144 [============================>.] - ETA: 0s - loss: 0.0749\n",
      "Epoch 47: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 9ms/step - loss: 0.0794 - val_loss: 0.2708\n",
      "Epoch 48/100\n",
      "141/144 [============================>.] - ETA: 0s - loss: 0.0688\n",
      "Epoch 48: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0679 - val_loss: 0.0054\n",
      "Epoch 49/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0732\n",
      "Epoch 49: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0721 - val_loss: 0.0225\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - ETA: 0s - loss: 0.0898\n",
      "Epoch 50: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0898 - val_loss: 0.2988\n",
      "Epoch 51/100\n",
      "138/144 [===========================>..] - ETA: 0s - loss: 0.0377\n",
      "Epoch 51: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0366 - val_loss: 0.0165\n",
      "Epoch 52/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 0.0837\n",
      "Epoch 52: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.0812 - val_loss: 0.0132\n",
      "Epoch 53/100\n",
      "138/144 [===========================>..] - ETA: 0s - loss: 0.0962\n",
      "Epoch 53: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0927 - val_loss: 0.0092\n",
      "Epoch 54/100\n",
      "142/144 [============================>.] - ETA: 0s - loss: 0.0224\n",
      "Epoch 54: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0245 - val_loss: 0.3218\n",
      "Epoch 55/100\n",
      "140/144 [============================>.] - ETA: 0s - loss: 0.0829\n",
      "Epoch 55: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 1s 10ms/step - loss: 0.0818 - val_loss: 0.0232\n",
      "Epoch 56/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 0.0564\n",
      "Epoch 56: val_loss did not improve from 0.00465\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.0553 - val_loss: 0.0143\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "Test Loss: 0.0047\n"
     ]
    }
   ],
   "source": [
    "# 과적합 방지하는 코드 추가\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "# 데이터 읽기\n",
    "df = pd.read_csv('data_drifter.csv')\n",
    "\n",
    "# 데이터 분할\n",
    "X = df[[ 'lons', 'lats', 'uo', 'vo', 'u10', 'v10']]\n",
    "y = df[['next_lons', 'next_lats']]\n",
    "\n",
    "# train, test 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 모델 구조 확인\n",
    "model.summary()\n",
    "\n",
    "#############################\n",
    "# 3. 학습 및 평가하기\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Early Stopping 콜백 정의\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)  # 10 epoch 동안 개선이 없으면 중단\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "# 학습 (Early Stopping 추가)\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.25, batch_size=64 ,verbose=1, callbacks=[early_stopping,model_checkpoint])\n",
    "\n",
    "# # 평가\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습된 모델로 경로 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n",
    "    ### 1-1. 초기값 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "drifter = pd.read_csv(\"drifter_2016.csv\")\n",
    "\n",
    "# 시간 변환 함수\n",
    "def convert_to_nearest_6hour(year, month, day, hour, minute):\n",
    "    # 데이터 값을 정수형으로 변환\n",
    "    year = int(year)\n",
    "    month = int(month)\n",
    "    day = int(day)\n",
    "    hour = int(hour)\n",
    "    minute = int(minute)\n",
    "\n",
    "    dt = datetime(year, month, day, hour, minute)\n",
    "    base_dt = datetime(2016, 1, 1, 0, 0)\n",
    "    delta = dt - base_dt\n",
    "    \n",
    "    hours_since_base = delta.total_seconds() / 3600\n",
    "    nearest_6hour = round(hours_since_base / 6) * 6\n",
    "\n",
    "    result_time = np.datetime64(base_dt + timedelta(hours=nearest_6hour))\n",
    "\n",
    "    return nearest_6hour, result_time\n",
    "\n",
    "# 결과를 저장할 리스트 생성\n",
    "results = []\n",
    "\n",
    "# .nc 파일 읽기\n",
    "dataset_sea = xr.open_dataset('interpolated_sea_2016.nc', engine='netcdf4')\n",
    "dataset_wind = xr.open_dataset('interpolated_wind_2016.nc', engine='netcdf4')\n",
    "# 각 시작 지점에 대한 처리\n",
    "for index, row in drifter.iterrows():\n",
    "    time, result_time = convert_to_nearest_6hour(row['Year'], row['Month'], row['Day'], row['Hour'], row['Minute'])\n",
    "    next_time = time + 6\n",
    "    \n",
    "    # uo, vo 값을 가져옴\n",
    "    uo_value = dataset_sea['uo'].sel(time=result_time, longitude=row['Longitude'], latitude=row['Latitude'], method='nearest').item()\n",
    "    vo_value = dataset_sea['vo'].sel(time=result_time, longitude=row['Longitude'], latitude=row['Latitude'], method='nearest').item()\n",
    "\n",
    "    # u10, v10 값을 가져옴\n",
    "    u10_value = dataset_wind['u10'].sel(time=result_time, longitude=row['Longitude'], latitude=row['Latitude'], method='nearest').item()\n",
    "    v10_value = dataset_wind['v10'].sel(time=result_time, longitude=row['Longitude'], latitude=row['Latitude'], method='nearest').item()\n",
    "\n",
    "    # 결과 저장\n",
    "    results.append({\n",
    "        'time': time,\n",
    "        'lons': row['Longitude'],\n",
    "        'lats': row['Latitude'],\n",
    "        'uo': uo_value,\n",
    "        'vo': vo_value,\n",
    "        'u10': u10_value,\n",
    "        'v10': v10_value,\n",
    "        'next_time': next_time\n",
    "    })\n",
    "\n",
    "dataset_sea.close()\n",
    "dataset_wind.close()\n",
    "\n",
    "# 리스트를 DataFrame으로 변환\n",
    "result_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lons</th>\n",
       "      <th>lats</th>\n",
       "      <th>uo</th>\n",
       "      <th>vo</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>next_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1740</td>\n",
       "      <td>127.071833</td>\n",
       "      <td>32.507367</td>\n",
       "      <td>-0.042594</td>\n",
       "      <td>0.163610</td>\n",
       "      <td>-3.698855</td>\n",
       "      <td>-5.244993</td>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1794</td>\n",
       "      <td>126.615817</td>\n",
       "      <td>33.759317</td>\n",
       "      <td>0.111659</td>\n",
       "      <td>0.156357</td>\n",
       "      <td>-1.989050</td>\n",
       "      <td>-1.670222</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1884</td>\n",
       "      <td>129.281933</td>\n",
       "      <td>34.949633</td>\n",
       "      <td>-0.039718</td>\n",
       "      <td>0.288225</td>\n",
       "      <td>-6.011956</td>\n",
       "      <td>-6.245036</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1884</td>\n",
       "      <td>129.212400</td>\n",
       "      <td>34.986667</td>\n",
       "      <td>-0.040380</td>\n",
       "      <td>0.272089</td>\n",
       "      <td>-4.942860</td>\n",
       "      <td>-5.878523</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4722</td>\n",
       "      <td>127.074467</td>\n",
       "      <td>32.516267</td>\n",
       "      <td>0.049979</td>\n",
       "      <td>0.304935</td>\n",
       "      <td>-2.538096</td>\n",
       "      <td>6.621501</td>\n",
       "      <td>4728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4788</td>\n",
       "      <td>129.297233</td>\n",
       "      <td>34.921750</td>\n",
       "      <td>0.203083</td>\n",
       "      <td>0.389139</td>\n",
       "      <td>1.072325</td>\n",
       "      <td>2.255833</td>\n",
       "      <td>4794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4824</td>\n",
       "      <td>129.398283</td>\n",
       "      <td>37.552583</td>\n",
       "      <td>0.025877</td>\n",
       "      <td>0.015028</td>\n",
       "      <td>-3.240538</td>\n",
       "      <td>1.653777</td>\n",
       "      <td>4830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time        lons       lats        uo        vo       u10       v10  \\\n",
       "0  1740  127.071833  32.507367 -0.042594  0.163610 -3.698855 -5.244993   \n",
       "1  1794  126.615817  33.759317  0.111659  0.156357 -1.989050 -1.670222   \n",
       "2  1884  129.281933  34.949633 -0.039718  0.288225 -6.011956 -6.245036   \n",
       "3  1884  129.212400  34.986667 -0.040380  0.272089 -4.942860 -5.878523   \n",
       "4  4722  127.074467  32.516267  0.049979  0.304935 -2.538096  6.621501   \n",
       "5  4788  129.297233  34.921750  0.203083  0.389139  1.072325  2.255833   \n",
       "6  4824  129.398283  37.552583  0.025877  0.015028 -3.240538  1.653777   \n",
       "\n",
       "   next_time  \n",
       "0       1746  \n",
       "1       1800  \n",
       "2       1890  \n",
       "3       1890  \n",
       "4       4728  \n",
       "5       4794  \n",
       "6       4830  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델로 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for index 0...\n",
      "inital value load for index 0...\n",
      "result : 1740.0, 127.07183333333332, 32.50736666666667, -0.042593646328896284, 0.16361024975776672, -3.69885516166687, -5.244993209838867, 1746.0\n",
      "Encountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 0 completed.\n",
      "Predicting for index 1...\n",
      "inital value load for index 1...\n",
      "result : 1794.0, 126.61581666666666, 33.75931666666666, 0.11165913939476013, 0.15635666251182556, -1.9890496730804443, -1.6702220439910889, 1800.0\n",
      "Encountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 1 completed.\n",
      "Predicting for index 2...\n",
      "inital value load for index 2...\n",
      "result : 1884.0, 129.28193333333334, 34.94963333333333, -0.03971831128001213, 0.28822505474090576, -6.011956214904785, -6.2450361251831055, 1890.0\n",
      "Encountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 2 completed.\n",
      "Predicting for index 3...\n",
      "inital value load for index 3...\n",
      "result : 1884.0, 129.2124, 34.986666666666665, -0.040380340069532394, 0.27208882570266724, -4.942860126495361, -5.878522872924805, 1890.0\n",
      "Encountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 3 completed.\n",
      "Predicting for index 4...\n",
      "inital value load for index 4...\n",
      "result : 4722.0, 127.07446666666668, 32.51626666666667, 0.049979022704064846, 0.30493471026420593, -2.538095712661743, 6.6215009689331055, 4728.0\n",
      "Encountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 4 completed.\n",
      "Predicting for index 5...\n",
      "inital value load for index 5...\n",
      "result : 4788.0, 129.29723333333334, 34.92175, 0.2030828446149826, 0.3891388177871704, 1.0723252296447754, 2.255833148956299, 4794.0\n",
      "Encountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 5 completed.\n",
      "Predicting for index 6...\n",
      "inital value load for index 6...\n",
      "result : 4824.0, 129.39828333333332, 37.55258333333333, 0.025877391919493675, 0.015027848072350025, -3.240537643432617, 1.6537771224975586, 4830.0\n",
      "Encountered a NaN value. Stopping the prediction loop.\n",
      "Predictions for index 6 completed.\n"
     ]
    }
   ],
   "source": [
    "# 각 시작 지점에서의 100일간 예측\n",
    "predict_duration = 400  # 100일 * 4 (하루에 6시간 단위로 4번 예측)\n",
    "\n",
    "# 예측 결과를 저장할 DataFrame\n",
    "predictions_df = pd.DataFrame(columns=['time', 'lons', 'lats', 'uo', 'vo', 'u10', 'v10', 'next_time', 'next_lons', 'next_lats'])\n",
    "\n",
    "# .nc 파일 읽기\n",
    "dataset_sea = xr.open_dataset('interpolated_sea_2016.nc', engine='netcdf4')\n",
    "dataset_wind = xr.open_dataset('interpolated_wind_2016.nc', engine='netcdf4')\n",
    "\n",
    "# 각 시작 지점 별로 for loop\n",
    "for index, row in result_df.iterrows():\n",
    "    print(f\"Predicting for index {index}...\")\n",
    "\n",
    "    # 초기값 불러오기\n",
    "    current_time = row['time']\n",
    "    current_lon = row['lons']\n",
    "    current_lat = row['lats']\n",
    "    uo_value = row['uo']\n",
    "    vo_value = row['vo']\n",
    "    u10_value = row['u10']\n",
    "    v10_value = row['v10']\n",
    "    next_time = row['next_time']\n",
    "    print(f\"inital value load for index {index}...\")\n",
    "    print(f\"result : {current_time}, {current_lon}, {current_lat}, {uo_value}, {vo_value}, {u10_value}, {v10_value}, {next_time}\")\n",
    "    predictions_list = []\n",
    "\n",
    "    # 100일간 예측\n",
    "    for _ in range(predict_duration):\n",
    "        #print(f\"predicting for {_}\", end=\"\")\n",
    "        # 모델에 입력값을 넣어 다음 위치를 예측합니다.\n",
    "        input_data = np.array([[current_lon, current_lat, uo_value, vo_value, u10_value, v10_value]])\n",
    "        input_data = input_data.reshape((input_data.shape[0], input_data.shape[1], 1))\n",
    "        \n",
    "        # 값 중에 nan이 있는지 확인\n",
    "        values_to_check = [current_time, current_lon, current_lat, uo_value, vo_value, u10_value, v10_value, next_time]\n",
    "        if any(np.isnan(value) for value in values_to_check):\n",
    "            print(\"Encountered a NaN value. Stopping the prediction loop.\")\n",
    "            break\n",
    "        \n",
    "        prediction = model.predict(input_data, verbose=0 )\n",
    "        \n",
    "        # 예측된 위치를 업데이트\n",
    "        predicted_lon = prediction[0][0]\n",
    "        predicted_lat = prediction[0][1]\n",
    "\n",
    "        #print(f\"result : {current_time}, {current_lon}, {current_lat}, {uo_value}, {vo_value}, {u10_value}, {v10_value}, {next_time}, {predicted_lon}, {predicted_lat}\", end=\"\")\n",
    "\n",
    "        predictions_list.append({\n",
    "            'time': current_time,\n",
    "            'lons': current_lon,\n",
    "            'lats': current_lat,\n",
    "            'uo': uo_value,\n",
    "            'vo': vo_value,\n",
    "            'u10': u10_value,\n",
    "            'v10': v10_value,\n",
    "            'next_time': next_time,\n",
    "            'next_lons': predicted_lon,\n",
    "            'next_lats': predicted_lat\n",
    "        })\n",
    "\n",
    "        \n",
    "        # 다음 반복을 위한 현재 위치와 시간 업데이트\n",
    "        current_lon = predicted_lon\n",
    "        current_lat = predicted_lat\n",
    "        current_time += 6 # 6시간 뒤로 이동\n",
    "        next_time += 6 # 6시간 뒤로 이동\n",
    "        \n",
    "        # 위도 경도 값을 가져오기 위한 시간 변환\n",
    "        base_dt = datetime(2016, 1, 1, 0, 0)\n",
    "        search_time = np.datetime64(base_dt + timedelta(hours=current_time))\n",
    "\n",
    "        # 현재 위치와 시간을 기반으로 uo, vo, u10, v10 값을 가져옵니다.\n",
    "        uo_value = dataset_sea['uo'].sel(time=search_time, longitude=current_lon, latitude=current_lat, method='nearest').item()\n",
    "        vo_value = dataset_sea['vo'].sel(time=search_time, longitude=current_lon, latitude=current_lat, method='nearest').item()\n",
    "        u10_value = dataset_wind['u10'].sel(time=search_time, longitude=current_lon, latitude=current_lat, method='nearest').item()\n",
    "        v10_value = dataset_wind['v10'].sel(time=search_time, longitude=current_lon, latitude=current_lat, method='nearest').item()\n",
    "    # 리스트를 DataFrame으로 변환\n",
    "    predictions_df = pd.DataFrame(predictions_list )\n",
    "    predictions_df.to_csv(f\"predictions_{index}.csv\", index=False)\n",
    "    print(f\"Predictions for index {index} completed.\")\n",
    "\n",
    "dataset_sea.close()\n",
    "dataset_wind.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
